{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.1.3-cp39-cp39-win_amd64.whl (7.6 MB)\n",
      "     ---------------------------------------- 7.6/7.6 MB 5.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\leeco\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from scikit-learn->sklearn) (1.8.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\leeco\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from scikit-learn->sklearn) (1.22.1)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting joblib>=1.0.0\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "     -------------------------------------- 298.0/298.0 KB 4.6 MB/s eta 0:00:00\n",
      "Using legacy 'setup.py install' for sklearn, since package 'wheel' is not installed.\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn, sklearn\n",
      "  Running setup.py install for sklearn: started\n",
      "  Running setup.py install for sklearn: finished with status 'done'\n",
      "Successfully installed joblib-1.2.0 scikit-learn-1.1.3 sklearn-0.0 threadpoolctl-3.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.3 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\leeco\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "#%pip install numpy\n",
    "#%pip install Pandas\n",
    "#%pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Horse Racing Results Predictor #\n",
    "\n",
    "The American professional gambler [Bill Benter](https://en.wikipedia.org/wiki/Bill_Benter) is said to have made earned nearly $1 billion through the development of one of the most successful analysis computer software programs in the horse racing market.\n",
    "\n",
    "Bill published his techniques in the paper [Computer-Based Horse Race Handicapping and Wagering Systems](https://www.gwern.net/docs/statistics/decision/1994-benter.pdf). \n",
    "\n",
    "The [YouTube Video by Ken Jee](https://www.youtube.com/watch?v=KEeUR8UDy-s) outlines how he did it, how difficult it was, and discusses whether it is likely to be able to replicate this feat today (hint: Ken thinks it highly unlikely for a number of reasons).\n",
    "\n",
    "Inspired by video, this notebook examines the possibility of replicating Bill's success using data from modern day UK races.\n",
    "\n",
    "NOTE: This is a fun examination of the technique the can be used in predicting races. It is not intended to be accurate or valid. The author accepts no responsibility for the correctness, completeness or quality of the information provided. Please do not use this information to place any real-world bets. Gambling odds are always skewed in favour of the bookmaker and you will lose in the long run.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from abc import ABC, abstractmethod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Load in the historic race data and ignore any horse that didn't complete the race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from datetime import timedelta\n",
    "results_files = glob.glob('Results_*.csv')\n",
    "results_files\n",
    "\n",
    "history = pd.concat([pd.read_csv(f) for f in results_files])\n",
    "history = history[history['ResultStatus'] == 'CompletedRace']\n",
    "history['Off'] =  pd.to_datetime(history['Off'], format='%m/%d/%Y %H:%M:%S')\n",
    "history['Wins'] = history.apply(lambda r: 1 if r['FinishingPosition'] == 1 else 0, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Define interface for processing the historic data and function to process data in a consistent way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RaceDataProcessor(ABC):\n",
    "    def initialize(self, history : pd.DataFrame) -> None:\n",
    "        # Initialise the processor with all historic data\n",
    "        self.history = history\n",
    "\n",
    "    def update(self, daily_results : pd.DataFrame) -> None:\n",
    "        # Update the processor with data\n",
    "        pass\n",
    "\n",
    "    def post_update(self, daily_results : pd.DataFrame) -> None:\n",
    "        # Merge daily_results with history ready for next day's data\n",
    "        self.history = pd.concat([self.history, daily_results])\n",
    "\n",
    "    def after_process_data(self) -> None:\n",
    "        # Allow processor to output results after processing completes\n",
    "        pass\n",
    "\n",
    "    def process_race_data(self, history : pd.DataFrame, days_to_process : int = 30):\n",
    "        history_end = history['Off'].max().date()\n",
    "        process_start = history_end - timedelta(days=days_to_process)\n",
    "        initial_history =  history[history['Off'].dt.date < process_start]   \n",
    "        self.initialize(initial_history)\n",
    "\n",
    "        while process_start < history_end:\n",
    "            process_step_end = process_start + timedelta(days=1)\n",
    "            daily_slice = history[(history['Off'].dt.date >= process_start) & (history['Off'].dt.date < process_step_end)]\n",
    "            self.update(daily_slice)\n",
    "            self.post_update(daily_slice)\n",
    "            process_start = process_step_end\n",
    "\n",
    "        self.after_process_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Check to see if we have a closed data set i.e. give all the previous history we know, how many races include horses that we have never seen race before? And how many times did those horses win races?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreviousRunnerAnalysisRaceDataProcessor(RaceDataProcessor):\n",
    "    def initialize(self, history : pd.DataFrame) -> None:\n",
    "        super().initialize(history)\n",
    "        self.__update_runner_stats()\n",
    "        self.__total_days = 0\n",
    "        self.__total_processed_races = 0\n",
    "        self.__total_known_runners = 0\n",
    "        self.__total_unknown_runners = 0\n",
    "        self.__total_winning_known_runners = 0\n",
    "        self.__total_winning_unknown_runners = 0\n",
    "        self.__total_races_with_unknown_runners = 0\n",
    "\n",
    "    def update(self, daily_results : pd.DataFrame) -> None:\n",
    "        self.__total_days += 1\n",
    "        self.__total_processed_races += daily_results['RaceId'].nunique()\n",
    "        unique_horse = daily_results['HorseId'].nunique()\n",
    "        known_unique_horse = daily_results[daily_results['HorseId'].isin(self.__known_runners)]['HorseId'].nunique()\n",
    "        self.__total_known_runners += known_unique_horse\n",
    "        self.__total_unknown_runners += unique_horse - known_unique_horse\n",
    "        winners = daily_results[daily_results['FinishingPosition'] == 1]\n",
    "        known_winners = winners[winners['HorseId'].isin(self.__known_runners)]['HorseId'].nunique()\n",
    "        self.__total_winning_known_runners += known_winners\n",
    "        self.__total_winning_unknown_runners += len(winners) - known_winners\n",
    "\n",
    "        races_with_known_runner_counts = daily_results.groupby('RaceId').apply(lambda df: self.__calculate_counts_for_race_group(df))\n",
    "        races_with_any_unknown_runners = races_with_known_runner_counts[races_with_known_runner_counts[\"HorseCount\"] != races_with_known_runner_counts[\"KnownHorseCount\"]]\n",
    "        self.__total_races_with_unknown_runners += races_with_any_unknown_runners.reset_index()['RaceId'].count()\n",
    "\n",
    "    def post_update(self, daily_results : pd.DataFrame) -> None:\n",
    "        super().post_update(daily_results)\n",
    "        self.__update_runner_stats()\n",
    "\n",
    "    def after_process_data(self) -> None:\n",
    "        percentage_unknown_runners = 100.0 * self.__total_unknown_runners / (self.__total_unknown_runners + self.__total_known_runners)\n",
    "        percentage_unknown_winners = 100.0 * self.__total_winning_unknown_runners / (self.__total_winning_unknown_runners + self.__total_winning_known_runners)\n",
    "        percentage_races_with_unknown_runners = 100.0 * self.__total_races_with_unknown_runners / (self.__total_races_with_unknown_runners + self.__total_processed_races)\n",
    "        print(\n",
    "            f'Previous runner data for last {self.__total_days} days / {self.__total_processed_races} races:\\n'\n",
    "            f'  Total known runners: {self.__total_known_runners}\\n'\n",
    "            f'  Total unknown runners: {self.__total_unknown_runners} ({percentage_unknown_runners:.2f} %)\\n'\n",
    "            f'  Total known winners: {self.__total_winning_known_runners}\\n'\n",
    "            f'  Total unknown winners: {self.__total_winning_unknown_runners} ({percentage_unknown_winners:.2f} %)\\n'\n",
    "            f'  Races with unknown runners: {self.__total_races_with_unknown_runners} ({percentage_races_with_unknown_runners:.2f} %)\\n'            \n",
    "            )\n",
    "        pass        \n",
    "\n",
    "    def __update_runner_stats(self) -> None:\n",
    "        self.__known_runners = self.history['HorseId'].unique().tolist()\n",
    "\n",
    "    def __calculate_counts_for_race_group(self, race_group) -> pd.Series:\n",
    "        new_columns = {}\n",
    "        new_columns['HorseCount'] = race_group['HorseId'].count()\n",
    "        new_columns['KnownHorseCount'] = race_group[race_group['HorseId'].isin(self.__known_runners)]['HorseId'].count()\n",
    "        return pd.Series(new_columns, index=['HorseCount', 'KnownHorseCount']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous runner data for last 30 days / 1651 races:\n",
      "  Total known runners: 14388\n",
      "  Total unknown runners: 1818 (11.22 %)\n",
      "  Total known winners: 1514\n",
      "  Total unknown winners: 445 (22.72 %)\n",
      "  Races with unknown runners: 593 (26.43 %)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PreviousRunnerAnalysisRaceDataProcessor().process_race_data(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions from Step 3**: 26.43 % of races include runners that have not previously run and a significant proportion of those are won by horses we have no prior data about. It is unlikely that we can predict with any accuracy these races given the lack of data.\n",
    "\n",
    "However, this also means that 73.57% of races *do* form a closed data set where we have prior information about races that we can use to inform predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: heck to see if we have a closed data set with respect to jockies i.e. give all the previous history we know, how many races include jockies that we have never seen race before? And how many times did those jockies win races?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreviousJockiesAnalysisRaceDataProcessor(RaceDataProcessor):\n",
    "    def initialize(self, history : pd.DataFrame) -> None:\n",
    "        super().initialize(history)\n",
    "        self.__update_jockey_stats()\n",
    "        self.__total_days = 0\n",
    "        self.__total_processed_races = 0\n",
    "        self.__total_known_jockies = 0\n",
    "        self.__total_unknown_jockies = 0\n",
    "        self.__total_winning_known_jockies = 0\n",
    "        self.__total_winning_unknown_jockies = 0\n",
    "        self.__total_races_with_unknown_jockies = 0\n",
    "\n",
    "    def update(self, daily_results : pd.DataFrame) -> None:\n",
    "        self.__total_days += 1\n",
    "        self.__total_processed_races += daily_results['RaceId'].nunique()\n",
    "        unique_jockies = daily_results['JockeyId'].nunique()\n",
    "        known_unique_jockies = daily_results[daily_results['JockeyId'].isin(self.__known_jockies)]['JockeyId'].nunique()\n",
    "        self.__total_known_jockies += known_unique_jockies\n",
    "        self.__total_unknown_jockies += unique_jockies - known_unique_jockies\n",
    "        winners = daily_results[daily_results['FinishingPosition'] == 1]\n",
    "        known_winners = winners[winners['JockeyId'].isin(self.__known_jockies)]['JockeyId'].nunique()\n",
    "        self.__total_winning_known_jockies += known_winners\n",
    "        self.__total_winning_unknown_jockies += len(winners) - known_winners\n",
    "\n",
    "        races_with_known_jockey_counts = daily_results.groupby('RaceId').apply(lambda df: self.__calculate_counts_for_race_group(df))\n",
    "        races_with_any_unknown_jockies = races_with_known_jockey_counts[races_with_known_jockey_counts[\"JockeyCount\"] != races_with_known_jockey_counts[\"KnownJockeyCount\"]]\n",
    "        self.__total_races_with_unknown_jockies += races_with_any_unknown_jockies.reset_index()['RaceId'].count()\n",
    "\n",
    "    def post_update(self, daily_results : pd.DataFrame) -> None:\n",
    "        super().post_update(daily_results)\n",
    "        self.__update_jockey_stats()\n",
    "\n",
    "    def after_process_data(self) -> None:\n",
    "        percentage_unknown_jockies = 100.0 * self.__total_unknown_jockies / (self.__total_unknown_jockies + self.__total_known_jockies)\n",
    "        percentage_unknown_winners = 100.0 * self.__total_winning_unknown_jockies / (self.__total_winning_unknown_jockies + self.__total_winning_known_jockies)\n",
    "        percentage_races_with_unknown_jockies = 100.0 * self.__total_races_with_unknown_jockies / (self.__total_races_with_unknown_jockies + self.__total_processed_races)\n",
    "        print(\n",
    "            f'Previous jockey data for last {self.__total_days} days / {self.__total_processed_races} races:\\n'\n",
    "            f'  Total known jockies: {self.__total_known_jockies}\\n'\n",
    "            f'  Total unknown jockies: {self.__total_unknown_jockies} ({percentage_unknown_jockies:.2f} %)\\n'\n",
    "            f'  Total known winners: {self.__total_winning_known_jockies}\\n'\n",
    "            f'  Total unknown winners: {self.__total_winning_unknown_jockies} ({percentage_unknown_winners:.2f} %)\\n'\n",
    "            f'  Races with unknown jockies: {self.__total_races_with_unknown_jockies} ({percentage_races_with_unknown_jockies:.2f} %)\\n'            \n",
    "            )\n",
    "        pass        \n",
    "\n",
    "    def __update_jockey_stats(self) -> None:\n",
    "        self.__known_jockies = self.history['JockeyId'].unique().tolist()\n",
    "\n",
    "    def __calculate_counts_for_race_group(self, race_group) -> pd.Series:\n",
    "        new_columns = {}\n",
    "        new_columns['JockeyCount'] = race_group['JockeyId'].count()\n",
    "        new_columns['KnownJockeyCount'] = race_group[race_group['JockeyId'].isin(self.__known_jockies)]['JockeyId'].count()\n",
    "        return pd.Series(new_columns, index=['JockeyCount', 'KnownJockeyCount']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous jockey data for last 30 days / 1651 races:\n",
      "  Total known jockies: 7723\n",
      "  Total unknown jockies: 57 (0.73 %)\n",
      "  Total known winners: 1422\n",
      "  Total unknown winners: 537 (27.41 %)\n",
      "  Races with unknown jockies: 43 (2.54 %)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PreviousJockiesAnalysisRaceDataProcessor().process_race_data(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions from Step 4**: A very small number of races include unknown jockies (2.54%). These races should be excluded from analysis for the same reasons outlined above for races with unknown horses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RaceDataProcessorIgnoringUnknownRunnersOrJockies(RaceDataProcessor):\n",
    "    def initialize(self, history : pd.DataFrame) -> None:\n",
    "        super().initialize(history)\n",
    "        self.__update_jockey_and_horse_stats()\n",
    "        self._total_races = 0\n",
    "        self._total_processed_races = 0\n",
    "        self._total_ignored_races = 0\n",
    "\n",
    "    def update(self, daily_results : pd.DataFrame) -> None:\n",
    "        self.process_filtered_results(self.__remove_races_with_unknown_horses_or_jockies(daily_results))\n",
    "        pass\n",
    "\n",
    "    def process_filtered_results(self, daily_results : pd.DataFrame) -> None:\n",
    "        pass\n",
    "\n",
    "    def post_update(self, daily_results : pd.DataFrame) -> None:\n",
    "        super().post_update(daily_results)\n",
    "        self.__update_jockey_and_horse_stats()\n",
    "\n",
    "    def __remove_races_with_unknown_horses_or_jockies(self, daily_results : pd.DataFrame) -> pd.DataFrame:\n",
    "        df = daily_results.groupby('RaceId').apply(lambda g: self.__calculate_counts_for_race_group(g))\n",
    "        races = daily_results['RaceId'].nunique()\n",
    "        self._total_races += races\n",
    "        df = df[(df['JockeyCount'] == df['KnownJockeyCount']) & (df['HorseCount'] == df['KnownHorseCount'])]\n",
    "        races_to_process = df.reset_index()['RaceId'].unique().tolist()\n",
    "        count_races_to_process = len(races_to_process)\n",
    "        self._total_processed_races += count_races_to_process\n",
    "        self._total_ignored_races += races - count_races_to_process\n",
    "        return daily_results[daily_results['RaceId'].isin(races_to_process)]\n",
    "\n",
    "    def __update_jockey_and_horse_stats(self) -> None:\n",
    "        self.__known_jockies = self.history['JockeyId'].unique().tolist()\n",
    "        self.__known_runners = self.history['HorseId'].unique().tolist()\n",
    "\n",
    "    def __calculate_counts_for_race_group(self, race_group) -> pd.Series:\n",
    "        new_columns = {}\n",
    "        new_columns['HorseCount'] = race_group['HorseId'].count()\n",
    "        new_columns['KnownHorseCount'] = race_group[race_group['HorseId'].isin(self.__known_runners)]['HorseId'].count()\n",
    "        new_columns['JockeyCount'] = race_group['JockeyId'].count()\n",
    "        new_columns['KnownJockeyCount'] = race_group[race_group['JockeyId'].isin(self.__known_jockies)]['JockeyId'].count()\n",
    "        return pd.Series(new_columns, index=['HorseCount', 'KnownHorseCount', 'JockeyCount', 'KnownJockeyCount']) \n",
    "    \n",
    "    def after_process_data(self) -> None:\n",
    "        print(\n",
    "            f'Processed {self._total_processed_races} of {self._total_races} races:\\n'\n",
    "            f'  Total ignored races: {self._total_ignored_races} (with unknown runner or jockey)'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1040 of 1651 races:\n",
      "  Total ignored races: 611 (with unknown runner or jockey)\n"
     ]
    }
   ],
   "source": [
    "RaceDataProcessorIgnoringUnknownRunnersOrJockies().process_race_data(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Baseline predictions by choosing the first horse on each race card. \n",
    "\n",
    "Should be fairly random and allow us to score more real predictions against dumb luck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RacePredictor(RaceDataProcessorIgnoringUnknownRunnersOrJockies):\n",
    "    def initialize(self, history: pd.DataFrame) -> None:\n",
    "        super().initialize(history)\n",
    "        self.__prediction_summary = pd.DataFrame(columns=['Date', 'Races', 'Predicted', 'Wins', 'Losses', 'Gains'])\n",
    "        self.__predictions = None\n",
    "\n",
    "    @property\n",
    "    def prediction_summary(self) -> pd.DataFrame:\n",
    "        return self.__prediction_summary \n",
    "\n",
    "    @property\n",
    "    def predictions(self) -> pd.DataFrame:\n",
    "        return self.__predictions\n",
    "\n",
    "    def _update_predictions(self, predictions: pd.DataFrame) -> None:\n",
    "        predicted = len(predictions)\n",
    "        if predicted > 0:\n",
    "            self.__predictions = predictions if self.__predictions is None else pd.concat([self.__predictions, predictions])\n",
    "            prediction_start = predictions.loc[predictions.index[0], 'Off']\n",
    "            staked = predicted # £1 stake per prediction\n",
    "            winners = predictions[predictions['PredictedPosition'] == predictions['FinishingPosition']]\n",
    "            wins = len(winners)\n",
    "            losses = predicted - wins\n",
    "            percentageWins = (wins / predicted) * 100.0;\n",
    "            winnings = winners['DecimalOdds'].sum()\n",
    "            percentageGains = ((winnings - losses) / staked) * 100.0;\n",
    "            # print(f'Scored: {predicted}, Won: {wins}, Winnings (with £1 stake): {winnings}, Lost: {losses}, %gains/loss: {percentageGains}')\n",
    "\n",
    "            row = pd.DataFrame([\n",
    "                {\n",
    "                    'Date': prediction_start, \n",
    "                    'Predicted': predicted, \n",
    "                    'Wins': wins, \n",
    "                    'Winnings': winnings,\n",
    "                    'Losses': losses,\n",
    "                    'PercentageWins': percentageWins,\n",
    "                    'GainLoss': winnings - staked, \n",
    "                    'PercentGainLoss': percentageGains\n",
    "                }])\n",
    "            self.__prediction_summary = pd.concat([self.__prediction_summary, row], axis=0, ignore_index=True)\n",
    "\n",
    "    def aggregate_prediction_summary(self) -> pd.DataFrame:\n",
    "        if len(self.__prediction_summary) == 0:\n",
    "            return pd.DataFrame(\n",
    "                data = {\n",
    "                    'Predicted': [0, 0, np.NAN, np.NAN, np.NAN, np.NAN], \n",
    "                    'Wins': [0, 0, np.NAN, np.NAN, np.NAN, np.NAN], \n",
    "                    'PercentageWins': [np.NAN, np.NAN, np.NAN, np.NAN, np.NAN, np.NAN],\n",
    "                    'GainLoss': [0, 0, 0, 0, 0, 0],\n",
    "                    'WinningsLoss': [0, 0, 0, 0, 0, 0]\n",
    "                }, \n",
    "                index=['average', 'sum', 'std', 'min', 'max', 'skew'])\n",
    "\n",
    "        return self.__prediction_summary.agg(\n",
    "            {\n",
    "                \"Predicted\" : [\"average\", \"sum\"],\n",
    "                \"Wins\" : [\"average\", \"sum\"],\n",
    "                \"PercentageWins\" : [\"average\", \"std\"],\n",
    "                \"GainLoss\": [\"min\", \"max\", \"average\", \"skew\", \"std\", \"sum\"],\n",
    "                \"Winnings\": [\"min\", \"max\", \"average\", \"skew\", \"std\", \"sum\"],\n",
    "            }\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FirstStallWinnerPredictor(RacePredictor):\n",
    "    def process_filtered_results(self, daily_results : pd.DataFrame) -> None:\n",
    "        predictions = daily_results.sort_values('RaceCardNumber', ascending=True).groupby('RaceId').first().copy()\n",
    "        predictions['PredictedPosition'] = 1\n",
    "        self._update_predictions(predictions)\n",
    "\n",
    "    def after_process_data(self) -> None:\n",
    "        super().after_process_data()\n",
    "        print(self.aggregate_prediction_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = FirstStallWinnerPredictor()\n",
    "predictor.process_race_data(history)\n",
    "predictor.predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions from Step 5**: Betting £1 randomly on 1040 races results in an overall loss of £156 :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6: Analyse factors to understand if they have influence on the outcome of races. Bill Benter suggested the following attributes:\n",
    "\n",
    "Current condition:\n",
    "- performance in recent races\n",
    "- time since last race\n",
    "- recent workout data\n",
    "- age of horse\n",
    "\n",
    "Past performance:\n",
    "- finishing position in past races\n",
    "- lengths behind winner in past races\n",
    "- normalized times of past races\n",
    "\n",
    "Adjustments to past performance:\n",
    "- strength of competition in past races\n",
    "- weight carried in past races\n",
    "- jockey's contribution to past performances\n",
    "- compensation for bad luck in past races\n",
    "- compensation for advantageous or disadvantageous post position in past races\n",
    "\n",
    "Present race situational factors:\n",
    "- weight to be carried\n",
    "- today's jockey's ability\n",
    "- advantages or disadvantages of the assigned post position\n",
    "\n",
    "Preferences which could influence the horse's performance in today's race:\n",
    "- distance preference\n",
    "- surface preference (turf vs dirt)\n",
    "- condition of surface preference (wet vs dry)\n",
    "- specific track preference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6.1: Define abstract feature factory for feature to the daily results that will be used to inform predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "class FeatureFactory:\n",
    "    @abstractmethod\n",
    "    def add_features(self, history: pd.DataFrame, daily_results : pd.DataFrame) -> pd.DataFrame:\n",
    "        pass\n",
    "\n",
    "\n",
    "class FeaturePredictor(RacePredictor):\n",
    "    def __init__(self, feature_factory: FeatureFactory) -> None:\n",
    "        super().__init__()\n",
    "        self.__feature_factory = feature_factory\n",
    "        self.__features = None\n",
    "\n",
    "    @property\n",
    "    def features(self):\n",
    "        return self.__features\n",
    "\n",
    "    def process_filtered_results(self, daily_results : pd.DataFrame) -> None:\n",
    "        daily_results_with_new_features = self.__feature_factory.add_features(self.history, daily_results.copy())\n",
    "        self.__features = daily_results_with_new_features if self.__features is None else pd.concat([self.__features, daily_results_with_new_features])\n",
    "        predictions = self.calculate_predictions(daily_results_with_new_features)\n",
    "        self._update_predictions(predictions)\n",
    "    \n",
    "    @abstractmethod\n",
    "    def calculate_predictions(self, daily_results : pd.DataFrame) -> pd.DataFrame:\n",
    "        pass\n",
    "\n",
    "    def after_process_data(self) -> None:\n",
    "        super().after_process_data()\n",
    "        print(self.aggregate_prediction_summary())\n",
    "\n",
    "\n",
    "class FeatureBuilder(RaceDataProcessorIgnoringUnknownRunnersOrJockies):\n",
    "    def __init__(self, feature_factories: List[FeatureFactory]) -> None:\n",
    "        super().__init__()\n",
    "        self.__feature_factories = feature_factories\n",
    "        self.__features = None\n",
    "\n",
    "    @property\n",
    "    def features(self):\n",
    "        return self.__features\n",
    "\n",
    "    def process_filtered_results(self, daily_results : pd.DataFrame) -> None:\n",
    "        daily_results_with_new_features = daily_results.copy()\n",
    "        for feature_factory in self.__feature_factories:\n",
    "            daily_results_with_new_features = feature_factory.add_features(self.history, daily_results_with_new_features)\n",
    "        self.__features = daily_results_with_new_features if self.__features is None else pd.concat([self.__features, daily_results_with_new_features])\n",
    "\n",
    "\n",
    "\n",
    "class LowestValueFeaturePredictor(FeaturePredictor):\n",
    "    def __init__(self, feature_factory: FeatureFactory, prediction_feature_name: str, drop_races_with_missing_feature: bool = False) -> None:\n",
    "        super().__init__(feature_factory)\n",
    "        self.__prediction_feature_name = prediction_feature_name\n",
    "        self.__drop_races_with_missing_features = drop_races_with_missing_feature\n",
    "\n",
    "    def calculate_predictions(self, daily_results: pd.DataFrame) -> pd.DataFrame:\n",
    "        if self.__drop_races_with_missing_features:\n",
    "            predictable = daily_results.groupby('RaceId').filter(lambda g: g.isnull().values.sum() == 0)\n",
    "        else:\n",
    "            predictable = daily_results.dropna(axis=0, subset=[self.__prediction_feature_name])\n",
    "\n",
    "        predictions = predictable.sort_values(self.__prediction_feature_name, ascending=True).groupby('RaceId').first().copy()\n",
    "        predictions['PredictedPosition'] = 1\n",
    "        return predictions\n",
    "\n",
    "\n",
    "class HighestValueFeaturePredictor(FeaturePredictor):\n",
    "    def __init__(self, feature_factory: FeatureFactory, prediction_feature_name: str, drop_races_with_missing_feature: bool = False) -> None:\n",
    "        super().__init__(feature_factory)\n",
    "        self.__prediction_feature_name = prediction_feature_name\n",
    "        self.__drop_races_with_missing_features = drop_races_with_missing_feature\n",
    "\n",
    "    def calculate_predictions(self, daily_results: pd.DataFrame) -> pd.DataFrame:\n",
    "        if self.__drop_races_with_missing_features:\n",
    "            predictable = daily_results.groupby('RaceId').filter(lambda g: g.isnull().values.sum() == 0)\n",
    "        else:\n",
    "            predictable = daily_results.dropna(axis=0, subset=[self.__prediction_feature_name])\n",
    "\n",
    "        predictions = predictable.sort_values(self.__prediction_feature_name, ascending=False).groupby('RaceId').first().copy()\n",
    "        predictions['PredictedPosition'] = 1\n",
    "        return predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6.2 Predict using performance in recent races. \n",
    "\n",
    "1. For each race in the last x months, sum the overall beaten distance and divide by the number of races (to average the performance over the period - since some horses may have ran more races than others in the given time frame)\n",
    "1. Predict that the horse with be best/lowers past performance will win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecentRacePerformanceFeatureFactory(FeatureFactory):\n",
    "    def __init__(self, days_to_process : int = 15) -> None:\n",
    "        super().__init__()\n",
    "        self.__days_to_process = days_to_process\n",
    "\n",
    "\n",
    "    def add_features(self, history: pd.DataFrame, daily_results: pd.DataFrame) -> pd.DataFrame:\n",
    "        history_end = history['Off'].max().date()\n",
    "        recent_history_start = history_end - timedelta(days=self.__days_to_process)\n",
    "        recent_history = history[history['Off'].dt.date >= recent_history_start]\n",
    "\n",
    "        horse_performance = recent_history.groupby('HorseId').apply(lambda g: self.__calculate_overall_horse_performance(g))\n",
    "\n",
    "        daily_results_with_new_features = pd.merge(daily_results, horse_performance, how='left', on=['HorseId'])\n",
    "        return daily_results_with_new_features\n",
    "\n",
    "    def __calculate_overall_horse_performance(self, race_group: pd.DataFrame) -> pd.Series:\n",
    "        new_columns = {}\n",
    "        new_columns['RaceCount'] = race_group['RaceId'].count()\n",
    "        new_columns['RecentPerformance'] = race_group['OverallBeatenDistance'].sum() / race_group['RaceId'].count()\n",
    "        return pd.Series(new_columns, index=['RaceCount', 'RecentPerformance']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting results using 30 days of recent history\n",
      "Processed 1040 of 1651 races:\n",
      "  Total ignored races: 611 (with unknown runner or jockey)\n",
      "           Predicted        Wins  PercentageWins    GainLoss    Winnings\n",
      "average    33.366667    5.866667       17.343934   -5.910401   27.456266\n",
      "sum      1001.000000  176.000000             NaN -177.312032  823.687968\n",
      "std              NaN         NaN        7.746484   13.360445   16.117111\n",
      "min              NaN         NaN             NaN  -29.000000    3.750000\n",
      "max              NaN         NaN             NaN   17.950000   66.900000\n",
      "skew             NaN         NaN             NaN    0.232433    0.776615\n",
      "  correlation = -0.11712525433480271\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(30, 31):\n",
    "    predictor = LowestValueFeaturePredictor(RecentRacePerformanceFeatureFactory(days_to_process=i), 'RecentPerformance')\n",
    "    print(f'Predicting results using {i} days of recent history')\n",
    "    predictor.process_race_data(history)\n",
    "    correlation = predictor.features[['Wins', 'RecentPerformance']].corr(method='spearman')['Wins']['RecentPerformance']\n",
    "    print(f'  correlation = {correlation}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6.3 Predict using jockey performance in recent races. \n",
    "\n",
    "1. For each race in the last x months, sum the overall beaten distance for a given jockey and divide by the number of races (to average the performance over the period - since some horses may have ran more races than others in the given time frame)\n",
    "1. Predict that the jockey with be best/lowers past performance will win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecentJockeyRacePerformanceFeatureFactory(FeatureFactory):\n",
    "    def __init__(self, days_to_process : int = 15) -> None:\n",
    "        super().__init__()\n",
    "        self.__days_to_process = days_to_process\n",
    "\n",
    "\n",
    "    def add_features(self, history: pd.DataFrame, daily_results: pd.DataFrame) -> pd.DataFrame:\n",
    "        history_end = history['Off'].max().date()\n",
    "        recent_history_start = history_end - timedelta(days=self.__days_to_process)\n",
    "        recent_history = history[history['Off'].dt.date >= recent_history_start]\n",
    "\n",
    "        jockey_performance = recent_history.groupby('JockeyId').apply(lambda g: self.__calculate_jockey_performance(g))\n",
    "\n",
    "        daily_results_with_new_features = pd.merge(daily_results, jockey_performance, how='left', on=['JockeyId'])\n",
    "        return daily_results_with_new_features\n",
    "\n",
    "    def __calculate_jockey_performance(self, race_group: pd.DataFrame) -> pd.Series:\n",
    "        new_columns = {}\n",
    "        new_columns['RaceCount'] = race_group['RaceId'].count()\n",
    "        new_columns['RecentJockeyPerformance'] = race_group['OverallBeatenDistance'].sum() / race_group['RaceId'].count()\n",
    "        return pd.Series(new_columns, index=['RaceCount', 'RecentJockeyPerformance']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting results using 30 days of recent jockey history\n",
      "Processed 1040 of 1651 races:\n",
      "  Total ignored races: 611 (with unknown runner or jockey)\n",
      "           Predicted        Wins  PercentageWins    GainLoss    Winnings\n",
      "average    34.666667    5.633333       16.324256   -5.227456   29.439211\n",
      "sum      1040.000000  169.000000             NaN -156.823665  883.176335\n",
      "std              NaN         NaN        7.787383   15.359460   17.800923\n",
      "min              NaN         NaN             NaN  -29.875000    0.000000\n",
      "max              NaN         NaN             NaN   45.000000   83.000000\n",
      "skew             NaN         NaN             NaN    0.989620    0.981410\n",
      "  correlation = -0.007379161185814985\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(30, 31):\n",
    "    predictor = LowestValueFeaturePredictor(RecentJockeyRacePerformanceFeatureFactory(days_to_process=i), 'RecentJockeyPerformance')\n",
    "    print(f'Predicting results using {i} days of recent jockey history')\n",
    "    predictor.process_race_data(history)\n",
    "    correlation = predictor.features[['Wins', 'RecentJockeyPerformance']].corr(method='spearman')['Wins']['RecentJockeyPerformance']\n",
    "    print(f'  correlation = {correlation}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1040 of 1651 races:\n",
      "  Total ignored races: 611 (with unknown runner or jockey)\n"
     ]
    }
   ],
   "source": [
    "builder = FeatureBuilder([RecentJockeyRacePerformanceFeatureFactory(), RecentRacePerformanceFeatureFactory()])\n",
    "builder.process_race_data(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = builder.features[['Wins', 'RecentJockeyPerformance', 'RecentPerformance', 'Age', 'WeightInPounds']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wins                       1.000000\n",
       "RecentJockeyPerformance   -0.000493\n",
       "RecentPerformance         -0.131942\n",
       "Age                        0.001105\n",
       "WeightInPounds             0.073938\n",
       "Name: Wins, dtype: float64"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.corr(method='spearman')['Wins']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([788103, 789883, 790782, 790879, 791829, 792761, 793815, 797156,\n",
       "       799413, 801518, 803396, 805316, 807665, 808654, 810119, 813972,\n",
       "       814917, 815892, 817697, 817886], dtype=int64)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_horses = history[['HorseId', 'RaceId']].groupby('HorseId').count().reset_index().sort_values('RaceId', ascending=False)['HorseId'].head(1).to_list()\n",
    "top_horse_races = history[history['HorseId'].isin(top_horses)]['RaceId'].unique()\n",
    "top_horse_races"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RaceType</th>\n",
       "      <th>WeightInPounds</th>\n",
       "      <th>HorseId</th>\n",
       "      <th>RaceId</th>\n",
       "      <th>Going</th>\n",
       "      <th>Wins</th>\n",
       "      <th>RaceTimeInSeconds</th>\n",
       "      <th>DistanceInMeters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2159</th>\n",
       "      <td>Other</td>\n",
       "      <td>145</td>\n",
       "      <td>3096972</td>\n",
       "      <td>788103</td>\n",
       "      <td>Good To Firm</td>\n",
       "      <td>0</td>\n",
       "      <td>73.580000</td>\n",
       "      <td>1206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9066</th>\n",
       "      <td>Other</td>\n",
       "      <td>138</td>\n",
       "      <td>3096972</td>\n",
       "      <td>789883</td>\n",
       "      <td>Good</td>\n",
       "      <td>0</td>\n",
       "      <td>63.360000</td>\n",
       "      <td>1105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>Other</td>\n",
       "      <td>139</td>\n",
       "      <td>3096972</td>\n",
       "      <td>790782</td>\n",
       "      <td>Good To Firm</td>\n",
       "      <td>1</td>\n",
       "      <td>57.640000</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2415</th>\n",
       "      <td>Other</td>\n",
       "      <td>139</td>\n",
       "      <td>3096972</td>\n",
       "      <td>790782</td>\n",
       "      <td>Good To Firm</td>\n",
       "      <td>1</td>\n",
       "      <td>57.640000</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5378</th>\n",
       "      <td>Other</td>\n",
       "      <td>145</td>\n",
       "      <td>3096972</td>\n",
       "      <td>790879</td>\n",
       "      <td>Good To Soft</td>\n",
       "      <td>0</td>\n",
       "      <td>69.893333</td>\n",
       "      <td>1105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6167</th>\n",
       "      <td>Other</td>\n",
       "      <td>145</td>\n",
       "      <td>3096972</td>\n",
       "      <td>790879</td>\n",
       "      <td>Good To Soft</td>\n",
       "      <td>0</td>\n",
       "      <td>69.893333</td>\n",
       "      <td>1105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14299</th>\n",
       "      <td>Other</td>\n",
       "      <td>144</td>\n",
       "      <td>3096972</td>\n",
       "      <td>791829</td>\n",
       "      <td>Good To Firm</td>\n",
       "      <td>1</td>\n",
       "      <td>57.520000</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15055</th>\n",
       "      <td>Other</td>\n",
       "      <td>144</td>\n",
       "      <td>3096972</td>\n",
       "      <td>791829</td>\n",
       "      <td>Good To Firm</td>\n",
       "      <td>1</td>\n",
       "      <td>57.520000</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5921</th>\n",
       "      <td>Other</td>\n",
       "      <td>146</td>\n",
       "      <td>3096972</td>\n",
       "      <td>792761</td>\n",
       "      <td>Good To Soft</td>\n",
       "      <td>0</td>\n",
       "      <td>79.245555</td>\n",
       "      <td>1206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6642</th>\n",
       "      <td>Other</td>\n",
       "      <td>146</td>\n",
       "      <td>3096972</td>\n",
       "      <td>792761</td>\n",
       "      <td>Good To Soft</td>\n",
       "      <td>0</td>\n",
       "      <td>79.245555</td>\n",
       "      <td>1206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13860</th>\n",
       "      <td>Other</td>\n",
       "      <td>148</td>\n",
       "      <td>3096972</td>\n",
       "      <td>793815</td>\n",
       "      <td>Standard</td>\n",
       "      <td>1</td>\n",
       "      <td>60.190000</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11224</th>\n",
       "      <td>Other</td>\n",
       "      <td>141</td>\n",
       "      <td>3096972</td>\n",
       "      <td>797156</td>\n",
       "      <td>Standard</td>\n",
       "      <td>1</td>\n",
       "      <td>59.540000</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>Other</td>\n",
       "      <td>144</td>\n",
       "      <td>3096972</td>\n",
       "      <td>799413</td>\n",
       "      <td>Standard To Slow</td>\n",
       "      <td>0</td>\n",
       "      <td>59.200000</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9381</th>\n",
       "      <td>Other</td>\n",
       "      <td>153</td>\n",
       "      <td>3096972</td>\n",
       "      <td>801518</td>\n",
       "      <td>Standard To Slow</td>\n",
       "      <td>0</td>\n",
       "      <td>59.360000</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10751</th>\n",
       "      <td>Other</td>\n",
       "      <td>144</td>\n",
       "      <td>3096972</td>\n",
       "      <td>803396</td>\n",
       "      <td>Standard</td>\n",
       "      <td>0</td>\n",
       "      <td>57.240000</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11251</th>\n",
       "      <td>Other</td>\n",
       "      <td>144</td>\n",
       "      <td>3096972</td>\n",
       "      <td>803396</td>\n",
       "      <td>Standard</td>\n",
       "      <td>0</td>\n",
       "      <td>57.240000</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9105</th>\n",
       "      <td>Other</td>\n",
       "      <td>152</td>\n",
       "      <td>3096972</td>\n",
       "      <td>805316</td>\n",
       "      <td>Good To Soft</td>\n",
       "      <td>0</td>\n",
       "      <td>72.395556</td>\n",
       "      <td>1206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9651</th>\n",
       "      <td>Other</td>\n",
       "      <td>152</td>\n",
       "      <td>3096972</td>\n",
       "      <td>805316</td>\n",
       "      <td>Good To Soft</td>\n",
       "      <td>0</td>\n",
       "      <td>72.395556</td>\n",
       "      <td>1206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24334</th>\n",
       "      <td>Other</td>\n",
       "      <td>152</td>\n",
       "      <td>3096972</td>\n",
       "      <td>805316</td>\n",
       "      <td>Good To Soft</td>\n",
       "      <td>0</td>\n",
       "      <td>72.395556</td>\n",
       "      <td>1206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24880</th>\n",
       "      <td>Other</td>\n",
       "      <td>152</td>\n",
       "      <td>3096972</td>\n",
       "      <td>805316</td>\n",
       "      <td>Good To Soft</td>\n",
       "      <td>0</td>\n",
       "      <td>72.395556</td>\n",
       "      <td>1206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8617</th>\n",
       "      <td>Other</td>\n",
       "      <td>149</td>\n",
       "      <td>3096972</td>\n",
       "      <td>807665</td>\n",
       "      <td>Standard</td>\n",
       "      <td>0</td>\n",
       "      <td>71.480000</td>\n",
       "      <td>1206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16920</th>\n",
       "      <td>Other</td>\n",
       "      <td>150</td>\n",
       "      <td>3096972</td>\n",
       "      <td>808654</td>\n",
       "      <td>Good</td>\n",
       "      <td>0</td>\n",
       "      <td>59.530000</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17539</th>\n",
       "      <td>Other</td>\n",
       "      <td>150</td>\n",
       "      <td>3096972</td>\n",
       "      <td>808654</td>\n",
       "      <td>Good</td>\n",
       "      <td>0</td>\n",
       "      <td>59.530000</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17797</th>\n",
       "      <td>Other</td>\n",
       "      <td>150</td>\n",
       "      <td>3096972</td>\n",
       "      <td>808654</td>\n",
       "      <td>Good</td>\n",
       "      <td>0</td>\n",
       "      <td>59.530000</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13028</th>\n",
       "      <td>Other</td>\n",
       "      <td>150</td>\n",
       "      <td>3096972</td>\n",
       "      <td>810119</td>\n",
       "      <td>Good</td>\n",
       "      <td>0</td>\n",
       "      <td>59.280000</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13585</th>\n",
       "      <td>Other</td>\n",
       "      <td>150</td>\n",
       "      <td>3096972</td>\n",
       "      <td>810119</td>\n",
       "      <td>Good</td>\n",
       "      <td>0</td>\n",
       "      <td>59.280000</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14468</th>\n",
       "      <td>Other</td>\n",
       "      <td>149</td>\n",
       "      <td>3096972</td>\n",
       "      <td>813972</td>\n",
       "      <td>Standard To Slow</td>\n",
       "      <td>0</td>\n",
       "      <td>74.060000</td>\n",
       "      <td>1206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14976</th>\n",
       "      <td>Other</td>\n",
       "      <td>149</td>\n",
       "      <td>3096972</td>\n",
       "      <td>813972</td>\n",
       "      <td>Standard To Slow</td>\n",
       "      <td>0</td>\n",
       "      <td>74.060000</td>\n",
       "      <td>1206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15174</th>\n",
       "      <td>Other</td>\n",
       "      <td>149</td>\n",
       "      <td>3096972</td>\n",
       "      <td>813972</td>\n",
       "      <td>Standard To Slow</td>\n",
       "      <td>0</td>\n",
       "      <td>74.060000</td>\n",
       "      <td>1206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4807</th>\n",
       "      <td>Other</td>\n",
       "      <td>145</td>\n",
       "      <td>3096972</td>\n",
       "      <td>814917</td>\n",
       "      <td>Good To Firm</td>\n",
       "      <td>0</td>\n",
       "      <td>58.120000</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4934</th>\n",
       "      <td>Other</td>\n",
       "      <td>145</td>\n",
       "      <td>3096972</td>\n",
       "      <td>814917</td>\n",
       "      <td>Good To Firm</td>\n",
       "      <td>0</td>\n",
       "      <td>58.120000</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5150</th>\n",
       "      <td>Other</td>\n",
       "      <td>145</td>\n",
       "      <td>3096972</td>\n",
       "      <td>814917</td>\n",
       "      <td>Good To Firm</td>\n",
       "      <td>0</td>\n",
       "      <td>58.120000</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11616</th>\n",
       "      <td>Other</td>\n",
       "      <td>156</td>\n",
       "      <td>3096972</td>\n",
       "      <td>815892</td>\n",
       "      <td>Good To Firm</td>\n",
       "      <td>0</td>\n",
       "      <td>71.310000</td>\n",
       "      <td>1206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11896</th>\n",
       "      <td>Other</td>\n",
       "      <td>156</td>\n",
       "      <td>3096972</td>\n",
       "      <td>815892</td>\n",
       "      <td>Good To Firm</td>\n",
       "      <td>0</td>\n",
       "      <td>71.310000</td>\n",
       "      <td>1206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8138</th>\n",
       "      <td>Other</td>\n",
       "      <td>152</td>\n",
       "      <td>3096972</td>\n",
       "      <td>817697</td>\n",
       "      <td>Good</td>\n",
       "      <td>0</td>\n",
       "      <td>65.680000</td>\n",
       "      <td>1105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8256</th>\n",
       "      <td>Other</td>\n",
       "      <td>152</td>\n",
       "      <td>3096972</td>\n",
       "      <td>817697</td>\n",
       "      <td>Good</td>\n",
       "      <td>0</td>\n",
       "      <td>65.680000</td>\n",
       "      <td>1105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12889</th>\n",
       "      <td>Other</td>\n",
       "      <td>148</td>\n",
       "      <td>3096972</td>\n",
       "      <td>817886</td>\n",
       "      <td>Good</td>\n",
       "      <td>0</td>\n",
       "      <td>62.040000</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13651</th>\n",
       "      <td>Other</td>\n",
       "      <td>148</td>\n",
       "      <td>3096972</td>\n",
       "      <td>817886</td>\n",
       "      <td>Good</td>\n",
       "      <td>0</td>\n",
       "      <td>62.040000</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13866</th>\n",
       "      <td>Other</td>\n",
       "      <td>148</td>\n",
       "      <td>3096972</td>\n",
       "      <td>817886</td>\n",
       "      <td>Good</td>\n",
       "      <td>0</td>\n",
       "      <td>62.040000</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      RaceType  WeightInPounds  HorseId  RaceId             Going  Wins  \\\n",
       "2159     Other             145  3096972  788103      Good To Firm     0   \n",
       "9066     Other             138  3096972  789883              Good     0   \n",
       "1541     Other             139  3096972  790782      Good To Firm     1   \n",
       "2415     Other             139  3096972  790782      Good To Firm     1   \n",
       "5378     Other             145  3096972  790879      Good To Soft     0   \n",
       "6167     Other             145  3096972  790879      Good To Soft     0   \n",
       "14299    Other             144  3096972  791829      Good To Firm     1   \n",
       "15055    Other             144  3096972  791829      Good To Firm     1   \n",
       "5921     Other             146  3096972  792761      Good To Soft     0   \n",
       "6642     Other             146  3096972  792761      Good To Soft     0   \n",
       "13860    Other             148  3096972  793815          Standard     1   \n",
       "11224    Other             141  3096972  797156          Standard     1   \n",
       "1054     Other             144  3096972  799413  Standard To Slow     0   \n",
       "9381     Other             153  3096972  801518  Standard To Slow     0   \n",
       "10751    Other             144  3096972  803396          Standard     0   \n",
       "11251    Other             144  3096972  803396          Standard     0   \n",
       "9105     Other             152  3096972  805316      Good To Soft     0   \n",
       "9651     Other             152  3096972  805316      Good To Soft     0   \n",
       "24334    Other             152  3096972  805316      Good To Soft     0   \n",
       "24880    Other             152  3096972  805316      Good To Soft     0   \n",
       "8617     Other             149  3096972  807665          Standard     0   \n",
       "16920    Other             150  3096972  808654              Good     0   \n",
       "17539    Other             150  3096972  808654              Good     0   \n",
       "17797    Other             150  3096972  808654              Good     0   \n",
       "13028    Other             150  3096972  810119              Good     0   \n",
       "13585    Other             150  3096972  810119              Good     0   \n",
       "14468    Other             149  3096972  813972  Standard To Slow     0   \n",
       "14976    Other             149  3096972  813972  Standard To Slow     0   \n",
       "15174    Other             149  3096972  813972  Standard To Slow     0   \n",
       "4807     Other             145  3096972  814917      Good To Firm     0   \n",
       "4934     Other             145  3096972  814917      Good To Firm     0   \n",
       "5150     Other             145  3096972  814917      Good To Firm     0   \n",
       "11616    Other             156  3096972  815892      Good To Firm     0   \n",
       "11896    Other             156  3096972  815892      Good To Firm     0   \n",
       "8138     Other             152  3096972  817697              Good     0   \n",
       "8256     Other             152  3096972  817697              Good     0   \n",
       "12889    Other             148  3096972  817886              Good     0   \n",
       "13651    Other             148  3096972  817886              Good     0   \n",
       "13866    Other             148  3096972  817886              Good     0   \n",
       "\n",
       "       RaceTimeInSeconds  DistanceInMeters  \n",
       "2159           73.580000              1206  \n",
       "9066           63.360000              1105  \n",
       "1541           57.640000              1005  \n",
       "2415           57.640000              1005  \n",
       "5378           69.893333              1105  \n",
       "6167           69.893333              1105  \n",
       "14299          57.520000              1005  \n",
       "15055          57.520000              1005  \n",
       "5921           79.245555              1206  \n",
       "6642           79.245555              1206  \n",
       "13860          60.190000              1005  \n",
       "11224          59.540000              1005  \n",
       "1054           59.200000              1005  \n",
       "9381           59.360000              1005  \n",
       "10751          57.240000              1005  \n",
       "11251          57.240000              1005  \n",
       "9105           72.395556              1206  \n",
       "9651           72.395556              1206  \n",
       "24334          72.395556              1206  \n",
       "24880          72.395556              1206  \n",
       "8617           71.480000              1206  \n",
       "16920          59.530000              1005  \n",
       "17539          59.530000              1005  \n",
       "17797          59.530000              1005  \n",
       "13028          59.280000              1005  \n",
       "13585          59.280000              1005  \n",
       "14468          74.060000              1206  \n",
       "14976          74.060000              1206  \n",
       "15174          74.060000              1206  \n",
       "4807           58.120000              1005  \n",
       "4934           58.120000              1005  \n",
       "5150           58.120000              1005  \n",
       "11616          71.310000              1206  \n",
       "11896          71.310000              1206  \n",
       "8138           65.680000              1105  \n",
       "8256           65.680000              1105  \n",
       "12889          62.040000              1005  \n",
       "13651          62.040000              1005  \n",
       "13866          62.040000              1005  "
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history[history['HorseId'].isin(top_horses)][['RaceType', 'WeightInPounds', 'HorseId', 'RaceId', 'Going', 'Wins', 'RaceTimeInSeconds', 'DistanceInMeters']]\n",
    "# TODO: calculate youngest horse in a given race, least weight \n",
    "# speed on course and going and adjust for weight carried\n",
    "# - how does these features correlate with wins?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RaceType</th>\n",
       "      <th>WeightInPounds</th>\n",
       "      <th>HorseId</th>\n",
       "      <th>RaceId</th>\n",
       "      <th>Wins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2153</th>\n",
       "      <td>Other</td>\n",
       "      <td>149</td>\n",
       "      <td>895486</td>\n",
       "      <td>788103</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2154</th>\n",
       "      <td>Other</td>\n",
       "      <td>133</td>\n",
       "      <td>1452882</td>\n",
       "      <td>788103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2155</th>\n",
       "      <td>Other</td>\n",
       "      <td>130</td>\n",
       "      <td>3130334</td>\n",
       "      <td>788103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2156</th>\n",
       "      <td>Other</td>\n",
       "      <td>123</td>\n",
       "      <td>893511</td>\n",
       "      <td>788103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157</th>\n",
       "      <td>Other</td>\n",
       "      <td>138</td>\n",
       "      <td>876967</td>\n",
       "      <td>788103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13864</th>\n",
       "      <td>Other</td>\n",
       "      <td>139</td>\n",
       "      <td>4017606</td>\n",
       "      <td>817886</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13865</th>\n",
       "      <td>Other</td>\n",
       "      <td>148</td>\n",
       "      <td>3096146</td>\n",
       "      <td>817886</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13866</th>\n",
       "      <td>Other</td>\n",
       "      <td>148</td>\n",
       "      <td>3096972</td>\n",
       "      <td>817886</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13867</th>\n",
       "      <td>Other</td>\n",
       "      <td>148</td>\n",
       "      <td>2036939</td>\n",
       "      <td>817886</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13868</th>\n",
       "      <td>Other</td>\n",
       "      <td>141</td>\n",
       "      <td>1448205</td>\n",
       "      <td>817886</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>460 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RaceType  WeightInPounds  HorseId  RaceId  Wins\n",
       "2153     Other             149   895486  788103     1\n",
       "2154     Other             133  1452882  788103     0\n",
       "2155     Other             130  3130334  788103     0\n",
       "2156     Other             123   893511  788103     0\n",
       "2157     Other             138   876967  788103     0\n",
       "...        ...             ...      ...     ...   ...\n",
       "13864    Other             139  4017606  817886     0\n",
       "13865    Other             148  3096146  817886     0\n",
       "13866    Other             148  3096972  817886     0\n",
       "13867    Other             148  2036939  817886     0\n",
       "13868    Other             141  1448205  817886     0\n",
       "\n",
       "[460 rows x 5 columns]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history[history['RaceId'].isin(top_horse_races)][['RaceType', 'WeightInPounds', 'HorseId', 'RaceId', 'Wins']]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8e284ee3255a07ad8bf76694974743c4c81cb57e7c969474d752d949b11d721e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
