{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install numpy\n",
    "#%pip install Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Horse Racing Results Predictor #\n",
    "\n",
    "The American professional gambler [Bill Benter](https://en.wikipedia.org/wiki/Bill_Benter) is said to have made earned nearly $1 billion through the development of one of the most successful analysis computer software programs in the horse racing market.\n",
    "\n",
    "Bill published his techniques in the paper [Computer-Based Horse Race Handicapping and Wagering Systems](https://www.gwern.net/docs/statistics/decision/1994-benter.pdf). \n",
    "\n",
    "The [YouTube Video by Ken Jee](https://www.youtube.com/watch?v=KEeUR8UDy-s) outlines how he did it, how difficult it was, and discusses whether it is likely to be able to replicate this feat today (hint: Ken thinks it highly unlikely for a number of reasons).\n",
    "\n",
    "Inspired by video, this notebook examines the possibility of replicating Bill's success using data from modern day UK races.\n",
    "\n",
    "NOTE: This is a fun examination of the technique the can be used in predicting races. It is not intended to be accurate or valid. The author accepts no responsibility for the correctness, completeness or quality of the information provided. Please do not use this information to place any real-world bets. Gambling odds are always skewed in favour of the bookmaker and you will lose in the long run.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from abc import ABC, abstractmethod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Load in the historic race data and ignore any horse that didn't complete the race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from datetime import timedelta\n",
    "results_files = glob.glob('Results_*.csv')\n",
    "results_files\n",
    "\n",
    "history = pd.concat([pd.read_csv(f) for f in results_files])\n",
    "history = history[history['ResultStatus'] == 'CompletedRace']\n",
    "history['Off'] =  pd.to_datetime(history['Off'], format='%m/%d/%Y %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Define interface for processing the historic data and function to process data in a consistent way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RaceDataProcessor(ABC):\n",
    "    def initialize(self, history : pd.DataFrame) -> None:\n",
    "        # Initialise the processor with all historic data\n",
    "        self.history = history\n",
    "\n",
    "    def update(self, daily_results : pd.DataFrame) -> None:\n",
    "        # Update the processor with data\n",
    "        pass\n",
    "\n",
    "    def post_update(self, daily_results : pd.DataFrame) -> None:\n",
    "        # Merge daily_results with history ready for next day's data\n",
    "        self.history = pd.concat([self.history, daily_results])\n",
    "\n",
    "    def after_process_data(self) -> None:\n",
    "        # Allow processor to output results after processing completes\n",
    "        pass\n",
    "\n",
    "    def process_race_data(self, history : pd.DataFrame, days_to_process : int = 30):\n",
    "        history_end = history['Off'].max().date()\n",
    "        process_start = history_end - timedelta(days=days_to_process)\n",
    "        initial_history =  history[history['Off'].dt.date < process_start]   \n",
    "        self.initialize(initial_history)\n",
    "\n",
    "        while process_start < history_end:\n",
    "            process_step_end = process_start + timedelta(days=1)\n",
    "            daily_slice = history[(history['Off'].dt.date >= process_start) & (history['Off'].dt.date < process_step_end)]\n",
    "            self.update(daily_slice)\n",
    "            self.post_update(daily_slice)\n",
    "            process_start = process_step_end\n",
    "\n",
    "        self.after_process_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Check to see if we have a closed data set i.e. give all the previous history we know, how many races include horses that we have never seen race before? And how many times did those horses win races?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreviousRunnerAnalysisRaceDataProcessor(RaceDataProcessor):\n",
    "    def initialize(self, history : pd.DataFrame) -> None:\n",
    "        super().initialize(history)\n",
    "        self.__update_runner_stats()\n",
    "        self.__total_days = 0\n",
    "        self.__total_processed_races = 0\n",
    "        self.__total_known_runners = 0\n",
    "        self.__total_unknown_runners = 0\n",
    "        self.__total_winning_known_runners = 0\n",
    "        self.__total_winning_unknown_runners = 0\n",
    "        self.__total_races_with_unknown_runners = 0\n",
    "\n",
    "    def update(self, daily_results : pd.DataFrame) -> None:\n",
    "        self.__total_days += 1\n",
    "        self.__total_processed_races += daily_results['RaceId'].nunique()\n",
    "        unique_horse = daily_results['HorseId'].nunique()\n",
    "        known_unique_horse = daily_results[daily_results['HorseId'].isin(self.__known_runners)]['HorseId'].nunique()\n",
    "        self.__total_known_runners += known_unique_horse\n",
    "        self.__total_unknown_runners += unique_horse - known_unique_horse\n",
    "        winners = daily_results[daily_results['FinishingPosition'] == 1]\n",
    "        known_winners = winners[winners['HorseId'].isin(self.__known_runners)]['HorseId'].nunique()\n",
    "        self.__total_winning_known_runners += known_winners\n",
    "        self.__total_winning_unknown_runners += len(winners) - known_winners\n",
    "\n",
    "        races_with_known_runner_counts = daily_results.groupby('RaceId').apply(lambda df: self.__calculate_counts_for_race_group(df))\n",
    "        races_with_any_unknown_runners = races_with_known_runner_counts[races_with_known_runner_counts[\"HorseCount\"] != races_with_known_runner_counts[\"KnownHorseCount\"]]\n",
    "        self.__total_races_with_unknown_runners += races_with_any_unknown_runners.reset_index()['RaceId'].count()\n",
    "\n",
    "    def post_update(self, daily_results : pd.DataFrame) -> None:\n",
    "        super().post_update(daily_results)\n",
    "        self.__update_runner_stats()\n",
    "\n",
    "    def after_process_data(self) -> None:\n",
    "        percentage_unknown_runners = 100.0 * self.__total_unknown_runners / (self.__total_unknown_runners + self.__total_known_runners)\n",
    "        percentage_unknown_winners = 100.0 * self.__total_winning_unknown_runners / (self.__total_winning_unknown_runners + self.__total_winning_known_runners)\n",
    "        percentage_races_with_unknown_runners = 100.0 * self.__total_races_with_unknown_runners / (self.__total_races_with_unknown_runners + self.__total_processed_races)\n",
    "        print(\n",
    "            f'Previous runner data for last {self.__total_days} days / {self.__total_processed_races} races:\\n'\n",
    "            f'  Total known runners: {self.__total_known_runners}\\n'\n",
    "            f'  Total unknown runners: {self.__total_unknown_runners} ({percentage_unknown_runners:.2f} %)\\n'\n",
    "            f'  Total known winners: {self.__total_winning_known_runners}\\n'\n",
    "            f'  Total unknown winners: {self.__total_winning_unknown_runners} ({percentage_unknown_winners:.2f} %)\\n'\n",
    "            f'  Races with unknown runners: {self.__total_races_with_unknown_runners} ({percentage_races_with_unknown_runners:.2f} %)\\n'            \n",
    "            )\n",
    "        pass        \n",
    "\n",
    "    def __update_runner_stats(self) -> None:\n",
    "        self.__known_runners = self.history['HorseId'].unique().tolist()\n",
    "\n",
    "    def __calculate_counts_for_race_group(self, race_group) -> pd.Series:\n",
    "        new_columns = {}\n",
    "        new_columns['HorseCount'] = race_group['HorseId'].count()\n",
    "        new_columns['KnownHorseCount'] = race_group[race_group['HorseId'].isin(self.__known_runners)]['HorseId'].count()\n",
    "        return pd.Series(new_columns, index=['HorseCount', 'KnownHorseCount']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous runner data for last 30 days / 1651 races:\n",
      "  Total known runners: 14388\n",
      "  Total unknown runners: 1818 (11.22 %)\n",
      "  Total known winners: 1514\n",
      "  Total unknown winners: 445 (22.72 %)\n",
      "  Races with unknown runners: 593 (26.43 %)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PreviousRunnerAnalysisRaceDataProcessor().process_race_data(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions from Step 3**: 26.43 % of races include runners that have not previously run and a significant proportion of those are won by horses we have no prior data about. It is unlikely that we can predict with any accuracy these races given the lack of data.\n",
    "\n",
    "However, this also means that 73.57% of races *do* form a closed data set where we have prior information about races that we can use to inform predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: heck to see if we have a closed data set with respect to jockies i.e. give all the previous history we know, how many races include jockies that we have never seen race before? And how many times did those jockies win races?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreviousJockiesAnalysisRaceDataProcessor(RaceDataProcessor):\n",
    "    def initialize(self, history : pd.DataFrame) -> None:\n",
    "        super().initialize(history)\n",
    "        self.__update_jockey_stats()\n",
    "        self.__total_days = 0\n",
    "        self.__total_processed_races = 0\n",
    "        self.__total_known_jockies = 0\n",
    "        self.__total_unknown_jockies = 0\n",
    "        self.__total_winning_known_jockies = 0\n",
    "        self.__total_winning_unknown_jockies = 0\n",
    "        self.__total_races_with_unknown_jockies = 0\n",
    "\n",
    "    def update(self, daily_results : pd.DataFrame) -> None:\n",
    "        self.__total_days += 1\n",
    "        self.__total_processed_races += daily_results['RaceId'].nunique()\n",
    "        unique_jockies = daily_results['JockeyId'].nunique()\n",
    "        known_unique_jockies = daily_results[daily_results['JockeyId'].isin(self.__known_jockies)]['JockeyId'].nunique()\n",
    "        self.__total_known_jockies += known_unique_jockies\n",
    "        self.__total_unknown_jockies += unique_jockies - known_unique_jockies\n",
    "        winners = daily_results[daily_results['FinishingPosition'] == 1]\n",
    "        known_winners = winners[winners['JockeyId'].isin(self.__known_jockies)]['JockeyId'].nunique()\n",
    "        self.__total_winning_known_jockies += known_winners\n",
    "        self.__total_winning_unknown_jockies += len(winners) - known_winners\n",
    "\n",
    "        races_with_known_jockey_counts = daily_results.groupby('RaceId').apply(lambda df: self.__calculate_counts_for_race_group(df))\n",
    "        races_with_any_unknown_jockies = races_with_known_jockey_counts[races_with_known_jockey_counts[\"JockeyCount\"] != races_with_known_jockey_counts[\"KnownJockeyCount\"]]\n",
    "        self.__total_races_with_unknown_jockies += races_with_any_unknown_jockies.reset_index()['RaceId'].count()\n",
    "\n",
    "    def post_update(self, daily_results : pd.DataFrame) -> None:\n",
    "        super().post_update(daily_results)\n",
    "        self.__update_jockey_stats()\n",
    "\n",
    "    def after_process_data(self) -> None:\n",
    "        percentage_unknown_jockies = 100.0 * self.__total_unknown_jockies / (self.__total_unknown_jockies + self.__total_known_jockies)\n",
    "        percentage_unknown_winners = 100.0 * self.__total_winning_unknown_jockies / (self.__total_winning_unknown_jockies + self.__total_winning_known_jockies)\n",
    "        percentage_races_with_unknown_jockies = 100.0 * self.__total_races_with_unknown_jockies / (self.__total_races_with_unknown_jockies + self.__total_processed_races)\n",
    "        print(\n",
    "            f'Previous jockey data for last {self.__total_days} days / {self.__total_processed_races} races:\\n'\n",
    "            f'  Total known jockies: {self.__total_known_jockies}\\n'\n",
    "            f'  Total unknown jockies: {self.__total_unknown_jockies} ({percentage_unknown_jockies:.2f} %)\\n'\n",
    "            f'  Total known winners: {self.__total_winning_known_jockies}\\n'\n",
    "            f'  Total unknown winners: {self.__total_winning_unknown_jockies} ({percentage_unknown_winners:.2f} %)\\n'\n",
    "            f'  Races with unknown jockies: {self.__total_races_with_unknown_jockies} ({percentage_races_with_unknown_jockies:.2f} %)\\n'            \n",
    "            )\n",
    "        pass        \n",
    "\n",
    "    def __update_jockey_stats(self) -> None:\n",
    "        self.__known_jockies = self.history['JockeyId'].unique().tolist()\n",
    "\n",
    "    def __calculate_counts_for_race_group(self, race_group) -> pd.Series:\n",
    "        new_columns = {}\n",
    "        new_columns['JockeyCount'] = race_group['JockeyId'].count()\n",
    "        new_columns['KnownJockeyCount'] = race_group[race_group['JockeyId'].isin(self.__known_jockies)]['JockeyId'].count()\n",
    "        return pd.Series(new_columns, index=['JockeyCount', 'KnownJockeyCount']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous jockey data for last 30 days / 1651 races:\n",
      "  Total known jockies: 7723\n",
      "  Total unknown jockies: 57 (0.73 %)\n",
      "  Total known winners: 1422\n",
      "  Total unknown winners: 537 (27.41 %)\n",
      "  Races with unknown jockies: 43 (2.54 %)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PreviousJockiesAnalysisRaceDataProcessor().process_race_data(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions from Step 4**: A very small number of races include unknown jockies (2.54%). These races should be excluded from analysis for the same reasons outlined above for races with unknown horses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RaceDataProcessorIgnoringUnknownRunnersOrJockies(RaceDataProcessor):\n",
    "    def initialize(self, history : pd.DataFrame) -> None:\n",
    "        super().initialize(history)\n",
    "        self.__update_jockey_and_horse_stats()\n",
    "        self._total_races = 0\n",
    "        self._total_processed_races = 0\n",
    "        self._total_ignored_races = 0\n",
    "\n",
    "    def update(self, daily_results : pd.DataFrame) -> None:\n",
    "        self.process_filtered_results(self.__remove_races_with_unknown_horses_or_jockies(daily_results))\n",
    "        pass\n",
    "\n",
    "    def process_filtered_results(self, daily_results : pd.DataFrame) -> None:\n",
    "        pass\n",
    "\n",
    "    def post_update(self, daily_results : pd.DataFrame) -> None:\n",
    "        super().post_update(daily_results)\n",
    "        self.__update_jockey_and_horse_stats()\n",
    "\n",
    "    def __remove_races_with_unknown_horses_or_jockies(self, daily_results : pd.DataFrame) -> pd.DataFrame:\n",
    "        df = daily_results.groupby('RaceId').apply(lambda g: self.__calculate_counts_for_race_group(g))\n",
    "        races = daily_results['RaceId'].nunique()\n",
    "        self._total_races += races\n",
    "        df = df[(df['JockeyCount'] == df['KnownJockeyCount']) & (df['HorseCount'] == df['KnownHorseCount'])]\n",
    "        races_to_process = df.reset_index()['RaceId'].unique().tolist()\n",
    "        count_races_to_process = len(races_to_process)\n",
    "        self._total_processed_races += count_races_to_process\n",
    "        self._total_ignored_races += races - count_races_to_process\n",
    "        return daily_results[daily_results['RaceId'].isin(races_to_process)]\n",
    "\n",
    "    def __update_jockey_and_horse_stats(self) -> None:\n",
    "        self.__known_jockies = self.history['JockeyId'].unique().tolist()\n",
    "        self.__known_runners = self.history['HorseId'].unique().tolist()\n",
    "\n",
    "    def __calculate_counts_for_race_group(self, race_group) -> pd.Series:\n",
    "        new_columns = {}\n",
    "        new_columns['HorseCount'] = race_group['HorseId'].count()\n",
    "        new_columns['KnownHorseCount'] = race_group[race_group['HorseId'].isin(self.__known_runners)]['HorseId'].count()\n",
    "        new_columns['JockeyCount'] = race_group['JockeyId'].count()\n",
    "        new_columns['KnownJockeyCount'] = race_group[race_group['JockeyId'].isin(self.__known_jockies)]['JockeyId'].count()\n",
    "        return pd.Series(new_columns, index=['HorseCount', 'KnownHorseCount', 'JockeyCount', 'KnownJockeyCount']) \n",
    "    \n",
    "    def after_process_data(self) -> None:\n",
    "        print(\n",
    "            f'Processed {self._total_processed_races} of {self._total_races} races:\\n'\n",
    "            f'  Total ignored races: {self._total_ignored_races} (with unknown runner or jockey)'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1040 of 1651 races:\n",
      "  Total ignored races: 611 (with unknown runner or jockey)\n"
     ]
    }
   ],
   "source": [
    "RaceDataProcessorIgnoringUnknownRunnersOrJockies().process_race_data(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Baseline predictions by choosing the first horse on each race card. \n",
    "\n",
    "Should be fairly random and allow us to score more real predictions against dumb luck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RacePredictor(RaceDataProcessorIgnoringUnknownRunnersOrJockies):\n",
    "    def initialize(self, history: pd.DataFrame) -> None:\n",
    "        super().initialize(history)\n",
    "        self.__prediction_summary = pd.DataFrame(columns=['Date', 'Races', 'Predicted', 'Wins', 'Losses', 'Gains'])\n",
    "        self.__predictions = None\n",
    "\n",
    "    @property\n",
    "    def prediction_summary(self) -> pd.DataFrame:\n",
    "        return self.__prediction_summary \n",
    "\n",
    "    @property\n",
    "    def predictions(self) -> pd.DataFrame:\n",
    "        return self.__predictions\n",
    "\n",
    "    def _update_predictions(self, predictions: pd.DataFrame) -> None:\n",
    "        predicted = len(predictions)\n",
    "        if predicted > 0:\n",
    "            self.__predictions = predictions if self.__predictions is None else pd.concat([self.__predictions, predictions])\n",
    "            prediction_start = predictions.loc[predictions.index[0], 'Off']\n",
    "            staked = predicted # £1 stake per prediction\n",
    "            winners = predictions[predictions['PredictedPosition'] == predictions['FinishingPosition']]\n",
    "            wins = len(winners)\n",
    "            losses = predicted - wins\n",
    "            percentageWins = (wins / predicted) * 100.0;\n",
    "            winnings = winners['DecimalOdds'].sum()\n",
    "            percentageGains = ((winnings - losses) / staked) * 100.0;\n",
    "            # print(f'Scored: {predicted}, Won: {wins}, Winnings (with £1 stake): {winnings}, Lost: {losses}, %gains/loss: {percentageGains}')\n",
    "\n",
    "            row = pd.DataFrame([\n",
    "                {\n",
    "                    'Date': prediction_start, \n",
    "                    'Predicted': predicted, \n",
    "                    'Wins': wins, \n",
    "                    'Winnings': winnings,\n",
    "                    'Losses': losses,\n",
    "                    'PercentageWins': percentageWins,\n",
    "                    'GainLoss': winnings - staked, \n",
    "                    'PercentGainLoss': percentageGains\n",
    "                }])\n",
    "            self.__prediction_summary = pd.concat([self.__prediction_summary, row], axis=0, ignore_index=True)\n",
    "\n",
    "    def aggregate_prediction_summary(self) -> pd.DataFrame:\n",
    "        return self.__prediction_summary.agg(\n",
    "            {\n",
    "                \"Predicted\" : [\"average\", \"sum\"],\n",
    "                \"Wins\" : [\"average\", \"sum\"],\n",
    "                \"PercentageWins\" : [\"average\", \"std\"],\n",
    "                \"GainLoss\": [\"min\", \"max\", \"average\", \"skew\", \"std\", \"sum\"],\n",
    "                \"Winnings\": [\"min\", \"max\", \"average\", \"skew\", \"std\", \"sum\"],\n",
    "            }\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FirstStallWinnerPredictor(RacePredictor):\n",
    "    def process_filtered_results(self, daily_results : pd.DataFrame) -> None:\n",
    "        predictions = daily_results.sort_values('RaceCardNumber', ascending=True).groupby('RaceId').first().copy()\n",
    "        predictions['PredictedPosition'] = 1\n",
    "        self._update_predictions(predictions)\n",
    "\n",
    "    def after_process_data(self) -> None:\n",
    "        super().after_process_data()\n",
    "        print(self.aggregate_prediction_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = FirstStallWinnerPredictor()\n",
    "predictor.process_race_data(history)\n",
    "predictor.predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions from Step 5**: Betting £1 randomly on 1040 races results in an overall loss of £156 :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6: Analyse factors to understand if they have influence on the outcome of races. Bill Benter suggested the following attributes:\n",
    "\n",
    "Current condition:\n",
    "- performance in recent races\n",
    "- time since last race\n",
    "- recent workout data\n",
    "- age of horse\n",
    "\n",
    "Past performance:\n",
    "- finishing position in past races\n",
    "- lengths behind winner in past races\n",
    "- normalized times of past races\n",
    "\n",
    "Adjustments to past performance:\n",
    "- strength of competition in past races\n",
    "- weight carried in past races\n",
    "- jockey's contribution to past performances\n",
    "- compensation for bad luck in past races\n",
    "- compensation for advantageous or disadvantageous post position in past races\n",
    "\n",
    "Present race situational factors:\n",
    "- weight to be carried\n",
    "- today's jockey's ability\n",
    "- advantages or disadvantages of the assigned post position\n",
    "\n",
    "Preferences which could influence the horse's performance in today's race:\n",
    "- distance preference\n",
    "- surface preference (turf vs dirt)\n",
    "- condition of surface preference (wet vs dry)\n",
    "- specific track preference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6.1: Define abstract feature factory for feature to the daily results that will be used to inform predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureFactory:\n",
    "    @abstractmethod\n",
    "    def add_features(self, history: pd.DataFrame, daily_results : pd.DataFrame) -> None:\n",
    "        pass\n",
    "\n",
    "\n",
    "class FeaturePredictor(RacePredictor):\n",
    "    def __init__(self, feature_factory: FeatureFactory) -> None:\n",
    "        super().__init__()\n",
    "        self.__feature_factory = feature_factory\n",
    "\n",
    "    def process_filtered_results(self, daily_results : pd.DataFrame) -> None:\n",
    "        daily_results_with_new_features = daily_results.copy()\n",
    "        self.__feature_factory.add_features(self.history, daily_results_with_new_features)\n",
    "        predictions = self.calculate_predictions(daily_results_with_new_features)\n",
    "        self._update_predictions(predictions)\n",
    "    \n",
    "    @abstractmethod\n",
    "    def calculate_predictions(self, daily_results : pd.DataFrame) -> pd.DataFrame:\n",
    "        pass\n",
    "\n",
    "    def after_process_data(self) -> None:\n",
    "        super().after_process_data()\n",
    "        print(self.aggregate_prediction_summary())\n",
    "\n",
    "\n",
    "class LowestValueFeaturePredictor(FeaturePredictor):\n",
    "    def __init__(self, feature_factory: FeatureFactory, prediction_feature_name: str) -> None:\n",
    "        super().__init__(feature_factory)\n",
    "        self.__prediction_feature_name = prediction_feature_name\n",
    "\n",
    "    def calculate_predictions(self, daily_results: pd.DataFrame) -> pd.DataFrame:\n",
    "        predictable = daily_results.dropna(axis=0, subset=[self.__prediction_feature_name])\n",
    "        predictions = predictable.sort_values(self.__prediction_feature_name, ascending=True).groupby('RaceId').first().copy()\n",
    "        predictions['PredictedPosition'] = 1\n",
    "        return predictions\n",
    "\n",
    "\n",
    "class HighestValueFeaturePredictor(FeaturePredictor):\n",
    "    def __init__(self, feature_factory: FeatureFactory, prediction_feature_name: str) -> None:\n",
    "        super().__init__(feature_factory)\n",
    "        self.__prediction_feature_name = prediction_feature_name\n",
    "\n",
    "    def calculate_predictions(self, daily_results: pd.DataFrame) -> pd.DataFrame:\n",
    "        predictable = daily_results.dropna(axis=0, subset=[self.__prediction_feature_name])\n",
    "        predictions = predictable.sort_values(self.__prediction_feature_name, ascending=False).groupby('RaceId').first().copy()\n",
    "        predictions['PredictedPosition'] = 1\n",
    "        return predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6.2 Predict using performance in recent races. \n",
    "\n",
    "1. For each race in the last x months, assign a score that is equal to the finishing position divided by the number of horses in the race (this assumes races with more runners are harder to win). \n",
    "2. Sum the per race performance score and divide by the number of races (to average the performance over the period - since some horses may have ran more races than others in the given time frame)\n",
    "3. Predict that the horse with be best/lowers past performance will win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecentRacePerformanceFeatureFactory(FeatureFactory):\n",
    "    def __init__(self, days_to_process : int = 30) -> None:\n",
    "        super().__init__()\n",
    "        self.__days_to_process = days_to_process\n",
    "\n",
    "\n",
    "    def add_features(self, history: pd.DataFrame, daily_results: pd.DataFrame) -> None:\n",
    "        history_end = history['Off'].max().date()\n",
    "        recent_history_start = history_end - timedelta(days=self.__days_to_process)\n",
    "        recent_history = history[history['Off'].dt.date >= recent_history_start]\n",
    "        \n",
    "        horses_per_race = recent_history.groupby('RaceId').apply(lambda g: self.__calculate_horse_counts_for_race_group(g))\n",
    "        recent_history = pd.merge(recent_history, horses_per_race, how='left', on=['RaceId'])\n",
    "        recent_history['RacePerformance'] = recent_history.apply(lambda row: self.__calculate_horse_race_performance(row), axis=1)\n",
    "        horse_performance = recent_history.groupby('HorseId').apply(lambda g: self.__calculate_overall_horse_performance(g))\n",
    "\n",
    "        daily_results = pd.merge(daily_results, horse_performance, how='left', on=['HorseId'])\n",
    "\n",
    "\n",
    "    def __calculate_horse_counts_for_race_group(self, race_group : pd.DataFrame) -> pd.Series:\n",
    "        new_columns = {}\n",
    "        new_columns['HorseCount'] = race_group['HorseId'].count()\n",
    "        return pd.Series(new_columns, index=['HorseCount']) \n",
    "\n",
    "\n",
    "    def __calculate_horse_race_performance(self, race_row : pd.DataFrame) -> float:\n",
    "        return race_row['FinishingPosition'] / race_row['HorseCount']\n",
    "\n",
    "\n",
    "    def __calculate_overall_horse_performance(self, race_group: pd.DataFrame) -> pd.Series:\n",
    "        new_columns = {}\n",
    "        new_columns['RaceCount'] = race_group['RaceId'].count()\n",
    "        new_columns['RecentPerformance'] = race_group['RacePerformance'].sum() / race_group['RaceId'].count()\n",
    "        return pd.Series(new_columns, index=['RaceCount', 'RecentPerformance']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1040 of 1651 races:\n",
      "  Total ignored races: 611 (with unknown runner or jockey)\n",
      "           Predicted        Wins  PercentageWins    GainLoss    Winnings\n",
      "average    34.666667    5.433333       16.058376   -5.319584   29.347083\n",
      "sum      1040.000000  163.000000             NaN -159.587518  880.412482\n",
      "std              NaN         NaN        6.733791   16.912677   17.139859\n",
      "min              NaN         NaN             NaN  -27.639394    5.500000\n",
      "max              NaN         NaN             NaN   33.000000   63.000000\n",
      "skew             NaN         NaN             NaN    0.604752    0.706429\n"
     ]
    }
   ],
   "source": [
    "predictor = LowestValueFeaturePredictor(RecentRacePerformanceFeatureFactory(), 'RecentPerformance')\n",
    "predictor.process_race_data(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HorseId</th>\n",
       "      <th>FinishingPosition</th>\n",
       "      <th>RecentPerformance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RaceId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>816969</th>\n",
       "      <td>4175288</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817906</th>\n",
       "      <td>2654569</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819625</th>\n",
       "      <td>1956567</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819626</th>\n",
       "      <td>2870506</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819627</th>\n",
       "      <td>4352816</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        HorseId  FinishingPosition  RecentPerformance\n",
       "RaceId                                               \n",
       "816969  4175288                  3                  1\n",
       "817906  2654569                  2                  1\n",
       "819625  1956567                 24                  1\n",
       "819626  2870506                  6                  1\n",
       "819627  4352816                 12                  1"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predictions[['HorseId', 'FinishingPosition', 'RecentPerformance']].head()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8e284ee3255a07ad8bf76694974743c4c81cb57e7c969474d752d949b11d721e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
