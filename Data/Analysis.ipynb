{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.1.3-cp39-cp39-win_amd64.whl (7.6 MB)\n",
      "     ---------------------------------------- 7.6/7.6 MB 5.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\leeco\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from scikit-learn->sklearn) (1.8.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\leeco\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from scikit-learn->sklearn) (1.22.1)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting joblib>=1.0.0\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "     -------------------------------------- 298.0/298.0 KB 4.6 MB/s eta 0:00:00\n",
      "Using legacy 'setup.py install' for sklearn, since package 'wheel' is not installed.\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn, sklearn\n",
      "  Running setup.py install for sklearn: started\n",
      "  Running setup.py install for sklearn: finished with status 'done'\n",
      "Successfully installed joblib-1.2.0 scikit-learn-1.1.3 sklearn-0.0 threadpoolctl-3.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.3 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\leeco\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "#%pip install numpy\n",
    "#%pip install Pandas\n",
    "#%pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Horse Racing Results Predictor #\n",
    "\n",
    "The American professional gambler [Bill Benter](https://en.wikipedia.org/wiki/Bill_Benter) is said to have made earned nearly $1 billion through the development of one of the most successful analysis computer software programs in the horse racing market.\n",
    "\n",
    "Bill published his techniques in the paper [Computer-Based Horse Race Handicapping and Wagering Systems](https://www.gwern.net/docs/statistics/decision/1994-benter.pdf). \n",
    "\n",
    "The [YouTube Video by Ken Jee](https://www.youtube.com/watch?v=KEeUR8UDy-s) outlines how he did it, how difficult it was, and discusses whether it is likely to be able to replicate this feat today (hint: Ken thinks it highly unlikely for a number of reasons).\n",
    "\n",
    "Inspired by video, this notebook examines the possibility of replicating Bill's success using data from modern day UK races.\n",
    "\n",
    "NOTE: This is a fun examination of the technique the can be used in predicting races. It is not intended to be accurate or valid. The author accepts no responsibility for the correctness, completeness or quality of the information provided. Please do not use this information to place any real-world bets. Gambling odds are always skewed in favour of the bookmaker and you will lose in the long run.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from abc import ABC, abstractmethod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Load in the historic race data and ignore any horse that didn't complete the race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from datetime import timedelta\n",
    "results_files = glob.glob('Results_*.csv')\n",
    "results_files\n",
    "\n",
    "history = pd.concat([pd.read_csv(f) for f in results_files])\n",
    "history = history[history['ResultStatus'] == 'CompletedRace']\n",
    "history['Off'] =  pd.to_datetime(history['Off'], format='%m/%d/%Y %H:%M:%S')\n",
    "history['Wins'] = history.apply(lambda r: 1 if r['FinishingPosition'] == 1 else 0, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Define interface for processing the historic data and function to process data in a consistent way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RaceDataProcessor(ABC):\n",
    "    def initialize(self, history : pd.DataFrame) -> None:\n",
    "        # Initialise the processor with all historic data\n",
    "        self.history = history\n",
    "\n",
    "    def update(self, daily_results : pd.DataFrame) -> None:\n",
    "        # Update the processor with data\n",
    "        pass\n",
    "\n",
    "    def post_update(self, daily_results : pd.DataFrame) -> None:\n",
    "        # Merge daily_results with history ready for next day's data\n",
    "        self.history = pd.concat([self.history, daily_results])\n",
    "\n",
    "    def after_process_data(self) -> None:\n",
    "        # Allow processor to output results after processing completes\n",
    "        pass\n",
    "\n",
    "    def process_race_data(self, history : pd.DataFrame, days_to_process : int = 30):\n",
    "        history_end = history['Off'].max().date()\n",
    "        process_start = history_end - timedelta(days=days_to_process)\n",
    "        initial_history =  history[history['Off'].dt.date < process_start]   \n",
    "        self.initialize(initial_history)\n",
    "\n",
    "        while process_start < history_end:\n",
    "            process_step_end = process_start + timedelta(days=1)\n",
    "            daily_slice = history[(history['Off'].dt.date >= process_start) & (history['Off'].dt.date < process_step_end)]\n",
    "            self.update(daily_slice)\n",
    "            self.post_update(daily_slice)\n",
    "            process_start = process_step_end\n",
    "\n",
    "        self.after_process_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Check to see if we have a closed data set i.e. give all the previous history we know, how many races include horses that we have never seen race before? And how many times did those horses win races?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreviousRunnerAnalysisRaceDataProcessor(RaceDataProcessor):\n",
    "    def initialize(self, history : pd.DataFrame) -> None:\n",
    "        super().initialize(history)\n",
    "        self.__update_runner_stats()\n",
    "        self.__total_days = 0\n",
    "        self.__total_processed_races = 0\n",
    "        self.__total_known_runners = 0\n",
    "        self.__total_unknown_runners = 0\n",
    "        self.__total_winning_known_runners = 0\n",
    "        self.__total_winning_unknown_runners = 0\n",
    "        self.__total_races_with_unknown_runners = 0\n",
    "\n",
    "    def update(self, daily_results : pd.DataFrame) -> None:\n",
    "        self.__total_days += 1\n",
    "        self.__total_processed_races += daily_results['RaceId'].nunique()\n",
    "        unique_horse = daily_results['HorseId'].nunique()\n",
    "        known_unique_horse = daily_results[daily_results['HorseId'].isin(self.__known_runners)]['HorseId'].nunique()\n",
    "        self.__total_known_runners += known_unique_horse\n",
    "        self.__total_unknown_runners += unique_horse - known_unique_horse\n",
    "        winners = daily_results[daily_results['FinishingPosition'] == 1]\n",
    "        known_winners = winners[winners['HorseId'].isin(self.__known_runners)]['HorseId'].nunique()\n",
    "        self.__total_winning_known_runners += known_winners\n",
    "        self.__total_winning_unknown_runners += len(winners) - known_winners\n",
    "\n",
    "        races_with_known_runner_counts = daily_results.groupby('RaceId').apply(lambda df: self.__calculate_counts_for_race_group(df))\n",
    "        races_with_any_unknown_runners = races_with_known_runner_counts[races_with_known_runner_counts[\"HorseCount\"] != races_with_known_runner_counts[\"KnownHorseCount\"]]\n",
    "        self.__total_races_with_unknown_runners += races_with_any_unknown_runners.reset_index()['RaceId'].count()\n",
    "\n",
    "    def post_update(self, daily_results : pd.DataFrame) -> None:\n",
    "        super().post_update(daily_results)\n",
    "        self.__update_runner_stats()\n",
    "\n",
    "    def after_process_data(self) -> None:\n",
    "        percentage_unknown_runners = 100.0 * self.__total_unknown_runners / (self.__total_unknown_runners + self.__total_known_runners)\n",
    "        percentage_unknown_winners = 100.0 * self.__total_winning_unknown_runners / (self.__total_winning_unknown_runners + self.__total_winning_known_runners)\n",
    "        percentage_races_with_unknown_runners = 100.0 * self.__total_races_with_unknown_runners / (self.__total_races_with_unknown_runners + self.__total_processed_races)\n",
    "        print(\n",
    "            f'Previous runner data for last {self.__total_days} days / {self.__total_processed_races} races:\\n'\n",
    "            f'  Total known runners: {self.__total_known_runners}\\n'\n",
    "            f'  Total unknown runners: {self.__total_unknown_runners} ({percentage_unknown_runners:.2f} %)\\n'\n",
    "            f'  Total known winners: {self.__total_winning_known_runners}\\n'\n",
    "            f'  Total unknown winners: {self.__total_winning_unknown_runners} ({percentage_unknown_winners:.2f} %)\\n'\n",
    "            f'  Races with unknown runners: {self.__total_races_with_unknown_runners} ({percentage_races_with_unknown_runners:.2f} %)\\n'            \n",
    "            )\n",
    "        pass        \n",
    "\n",
    "    def __update_runner_stats(self) -> None:\n",
    "        self.__known_runners = self.history['HorseId'].unique().tolist()\n",
    "\n",
    "    def __calculate_counts_for_race_group(self, race_group) -> pd.Series:\n",
    "        new_columns = {}\n",
    "        new_columns['HorseCount'] = race_group['HorseId'].count()\n",
    "        new_columns['KnownHorseCount'] = race_group[race_group['HorseId'].isin(self.__known_runners)]['HorseId'].count()\n",
    "        return pd.Series(new_columns, index=['HorseCount', 'KnownHorseCount']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous runner data for last 30 days / 1651 races:\n",
      "  Total known runners: 14388\n",
      "  Total unknown runners: 1818 (11.22 %)\n",
      "  Total known winners: 1514\n",
      "  Total unknown winners: 445 (22.72 %)\n",
      "  Races with unknown runners: 593 (26.43 %)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PreviousRunnerAnalysisRaceDataProcessor().process_race_data(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions from Step 3**: 26.43 % of races include runners that have not previously run and a significant proportion of those are won by horses we have no prior data about. It is unlikely that we can predict with any accuracy these races given the lack of data.\n",
    "\n",
    "However, this also means that 73.57% of races *do* form a closed data set where we have prior information about races that we can use to inform predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: heck to see if we have a closed data set with respect to jockies i.e. give all the previous history we know, how many races include jockies that we have never seen race before? And how many times did those jockies win races?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreviousJockiesAnalysisRaceDataProcessor(RaceDataProcessor):\n",
    "    def initialize(self, history : pd.DataFrame) -> None:\n",
    "        super().initialize(history)\n",
    "        self.__update_jockey_stats()\n",
    "        self.__total_days = 0\n",
    "        self.__total_processed_races = 0\n",
    "        self.__total_known_jockies = 0\n",
    "        self.__total_unknown_jockies = 0\n",
    "        self.__total_winning_known_jockies = 0\n",
    "        self.__total_winning_unknown_jockies = 0\n",
    "        self.__total_races_with_unknown_jockies = 0\n",
    "\n",
    "    def update(self, daily_results : pd.DataFrame) -> None:\n",
    "        self.__total_days += 1\n",
    "        self.__total_processed_races += daily_results['RaceId'].nunique()\n",
    "        unique_jockies = daily_results['JockeyId'].nunique()\n",
    "        known_unique_jockies = daily_results[daily_results['JockeyId'].isin(self.__known_jockies)]['JockeyId'].nunique()\n",
    "        self.__total_known_jockies += known_unique_jockies\n",
    "        self.__total_unknown_jockies += unique_jockies - known_unique_jockies\n",
    "        winners = daily_results[daily_results['FinishingPosition'] == 1]\n",
    "        known_winners = winners[winners['JockeyId'].isin(self.__known_jockies)]['JockeyId'].nunique()\n",
    "        self.__total_winning_known_jockies += known_winners\n",
    "        self.__total_winning_unknown_jockies += len(winners) - known_winners\n",
    "\n",
    "        races_with_known_jockey_counts = daily_results.groupby('RaceId').apply(lambda df: self.__calculate_counts_for_race_group(df))\n",
    "        races_with_any_unknown_jockies = races_with_known_jockey_counts[races_with_known_jockey_counts[\"JockeyCount\"] != races_with_known_jockey_counts[\"KnownJockeyCount\"]]\n",
    "        self.__total_races_with_unknown_jockies += races_with_any_unknown_jockies.reset_index()['RaceId'].count()\n",
    "\n",
    "    def post_update(self, daily_results : pd.DataFrame) -> None:\n",
    "        super().post_update(daily_results)\n",
    "        self.__update_jockey_stats()\n",
    "\n",
    "    def after_process_data(self) -> None:\n",
    "        percentage_unknown_jockies = 100.0 * self.__total_unknown_jockies / (self.__total_unknown_jockies + self.__total_known_jockies)\n",
    "        percentage_unknown_winners = 100.0 * self.__total_winning_unknown_jockies / (self.__total_winning_unknown_jockies + self.__total_winning_known_jockies)\n",
    "        percentage_races_with_unknown_jockies = 100.0 * self.__total_races_with_unknown_jockies / (self.__total_races_with_unknown_jockies + self.__total_processed_races)\n",
    "        print(\n",
    "            f'Previous jockey data for last {self.__total_days} days / {self.__total_processed_races} races:\\n'\n",
    "            f'  Total known jockies: {self.__total_known_jockies}\\n'\n",
    "            f'  Total unknown jockies: {self.__total_unknown_jockies} ({percentage_unknown_jockies:.2f} %)\\n'\n",
    "            f'  Total known winners: {self.__total_winning_known_jockies}\\n'\n",
    "            f'  Total unknown winners: {self.__total_winning_unknown_jockies} ({percentage_unknown_winners:.2f} %)\\n'\n",
    "            f'  Races with unknown jockies: {self.__total_races_with_unknown_jockies} ({percentage_races_with_unknown_jockies:.2f} %)\\n'            \n",
    "            )\n",
    "        pass        \n",
    "\n",
    "    def __update_jockey_stats(self) -> None:\n",
    "        self.__known_jockies = self.history['JockeyId'].unique().tolist()\n",
    "\n",
    "    def __calculate_counts_for_race_group(self, race_group) -> pd.Series:\n",
    "        new_columns = {}\n",
    "        new_columns['JockeyCount'] = race_group['JockeyId'].count()\n",
    "        new_columns['KnownJockeyCount'] = race_group[race_group['JockeyId'].isin(self.__known_jockies)]['JockeyId'].count()\n",
    "        return pd.Series(new_columns, index=['JockeyCount', 'KnownJockeyCount']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous jockey data for last 30 days / 1651 races:\n",
      "  Total known jockies: 7723\n",
      "  Total unknown jockies: 57 (0.73 %)\n",
      "  Total known winners: 1422\n",
      "  Total unknown winners: 537 (27.41 %)\n",
      "  Races with unknown jockies: 43 (2.54 %)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PreviousJockiesAnalysisRaceDataProcessor().process_race_data(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions from Step 4**: A very small number of races include unknown jockies (2.54%). These races should be excluded from analysis for the same reasons outlined above for races with unknown horses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RaceDataProcessorIgnoringUnknownRunnersOrJockies(RaceDataProcessor):\n",
    "    def initialize(self, history : pd.DataFrame) -> None:\n",
    "        super().initialize(history)\n",
    "        self.__update_jockey_and_horse_stats()\n",
    "        self._total_races = 0\n",
    "        self._total_processed_races = 0\n",
    "        self._total_ignored_races = 0\n",
    "\n",
    "    def update(self, daily_results : pd.DataFrame) -> None:\n",
    "        self.process_filtered_results(self.__remove_races_with_unknown_horses_or_jockies(daily_results))\n",
    "        pass\n",
    "\n",
    "    def process_filtered_results(self, daily_results : pd.DataFrame) -> None:\n",
    "        pass\n",
    "\n",
    "    def post_update(self, daily_results : pd.DataFrame) -> None:\n",
    "        super().post_update(daily_results)\n",
    "        self.__update_jockey_and_horse_stats()\n",
    "\n",
    "    def __remove_races_with_unknown_horses_or_jockies(self, daily_results : pd.DataFrame) -> pd.DataFrame:\n",
    "        df = daily_results.groupby('RaceId').apply(lambda g: self.__calculate_counts_for_race_group(g))\n",
    "        races = daily_results['RaceId'].nunique()\n",
    "        self._total_races += races\n",
    "        df = df[(df['JockeyCount'] == df['KnownJockeyCount']) & (df['HorseCount'] == df['KnownHorseCount'])]\n",
    "        races_to_process = df.reset_index()['RaceId'].unique().tolist()\n",
    "        count_races_to_process = len(races_to_process)\n",
    "        self._total_processed_races += count_races_to_process\n",
    "        self._total_ignored_races += races - count_races_to_process\n",
    "        return daily_results[daily_results['RaceId'].isin(races_to_process)]\n",
    "\n",
    "    def __update_jockey_and_horse_stats(self) -> None:\n",
    "        self.__known_jockies = self.history['JockeyId'].unique().tolist()\n",
    "        self.__known_runners = self.history['HorseId'].unique().tolist()\n",
    "\n",
    "    def __calculate_counts_for_race_group(self, race_group) -> pd.Series:\n",
    "        new_columns = {}\n",
    "        new_columns['HorseCount'] = race_group['HorseId'].count()\n",
    "        new_columns['KnownHorseCount'] = race_group[race_group['HorseId'].isin(self.__known_runners)]['HorseId'].count()\n",
    "        new_columns['JockeyCount'] = race_group['JockeyId'].count()\n",
    "        new_columns['KnownJockeyCount'] = race_group[race_group['JockeyId'].isin(self.__known_jockies)]['JockeyId'].count()\n",
    "        return pd.Series(new_columns, index=['HorseCount', 'KnownHorseCount', 'JockeyCount', 'KnownJockeyCount']) \n",
    "    \n",
    "    def after_process_data(self) -> None:\n",
    "        print(\n",
    "            f'Processed {self._total_processed_races} of {self._total_races} races:\\n'\n",
    "            f'  Total ignored races: {self._total_ignored_races} (with unknown runner or jockey)'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1040 of 1651 races:\n",
      "  Total ignored races: 611 (with unknown runner or jockey)\n"
     ]
    }
   ],
   "source": [
    "RaceDataProcessorIgnoringUnknownRunnersOrJockies().process_race_data(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Baseline predictions by choosing the first horse on each race card. \n",
    "\n",
    "Should be fairly random and allow us to score more real predictions against dumb luck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RacePredictor(RaceDataProcessorIgnoringUnknownRunnersOrJockies):\n",
    "    def initialize(self, history: pd.DataFrame) -> None:\n",
    "        super().initialize(history)\n",
    "        self.__prediction_summary = pd.DataFrame(columns=['Date', 'Races', 'Predicted', 'Wins', 'Losses', 'Gains'])\n",
    "        self.__predictions = None\n",
    "\n",
    "    @property\n",
    "    def prediction_summary(self) -> pd.DataFrame:\n",
    "        return self.__prediction_summary \n",
    "\n",
    "    @property\n",
    "    def predictions(self) -> pd.DataFrame:\n",
    "        return self.__predictions\n",
    "\n",
    "    def _update_predictions(self, predictions: pd.DataFrame) -> None:\n",
    "        predicted = len(predictions)\n",
    "        if predicted > 0:\n",
    "            self.__predictions = predictions if self.__predictions is None else pd.concat([self.__predictions, predictions])\n",
    "            prediction_start = predictions.loc[predictions.index[0], 'Off']\n",
    "            staked = predicted # £1 stake per prediction\n",
    "            winners = predictions[predictions['PredictedPosition'] == predictions['FinishingPosition']]\n",
    "            wins = len(winners)\n",
    "            losses = predicted - wins\n",
    "            percentageWins = (wins / predicted) * 100.0;\n",
    "            winnings = winners['DecimalOdds'].sum()\n",
    "            percentageGains = ((winnings - losses) / staked) * 100.0;\n",
    "            # print(f'Scored: {predicted}, Won: {wins}, Winnings (with £1 stake): {winnings}, Lost: {losses}, %gains/loss: {percentageGains}')\n",
    "\n",
    "            row = pd.DataFrame([\n",
    "                {\n",
    "                    'Date': prediction_start, \n",
    "                    'Predicted': predicted, \n",
    "                    'Wins': wins, \n",
    "                    'Winnings': winnings,\n",
    "                    'Losses': losses,\n",
    "                    'PercentageWins': percentageWins,\n",
    "                    'GainLoss': winnings - staked, \n",
    "                    'PercentGainLoss': percentageGains\n",
    "                }])\n",
    "            self.__prediction_summary = pd.concat([self.__prediction_summary, row], axis=0, ignore_index=True)\n",
    "\n",
    "    def aggregate_prediction_summary(self) -> pd.DataFrame:\n",
    "        if len(self.__prediction_summary) == 0:\n",
    "            return pd.DataFrame(\n",
    "                data = {\n",
    "                    'Predicted': [0, 0, np.NAN, np.NAN, np.NAN, np.NAN], \n",
    "                    'Wins': [0, 0, np.NAN, np.NAN, np.NAN, np.NAN], \n",
    "                    'PercentageWins': [np.NAN, np.NAN, np.NAN, np.NAN, np.NAN, np.NAN],\n",
    "                    'GainLoss': [0, 0, 0, 0, 0, 0],\n",
    "                    'WinningsLoss': [0, 0, 0, 0, 0, 0]\n",
    "                }, \n",
    "                index=['average', 'sum', 'std', 'min', 'max', 'skew'])\n",
    "\n",
    "        return self.__prediction_summary.agg(\n",
    "            {\n",
    "                \"Predicted\" : [\"average\", \"sum\"],\n",
    "                \"Wins\" : [\"average\", \"sum\"],\n",
    "                \"PercentageWins\" : [\"average\", \"std\"],\n",
    "                \"GainLoss\": [\"min\", \"max\", \"average\", \"skew\", \"std\", \"sum\"],\n",
    "                \"Winnings\": [\"min\", \"max\", \"average\", \"skew\", \"std\", \"sum\"],\n",
    "            }\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FirstStallWinnerPredictor(RacePredictor):\n",
    "    def process_filtered_results(self, daily_results : pd.DataFrame) -> None:\n",
    "        predictions = daily_results.sort_values('RaceCardNumber', ascending=True).groupby('RaceId').first().copy()\n",
    "        predictions['PredictedPosition'] = 1\n",
    "        self._update_predictions(predictions)\n",
    "\n",
    "    def after_process_data(self) -> None:\n",
    "        super().after_process_data()\n",
    "        print(self.aggregate_prediction_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = FirstStallWinnerPredictor()\n",
    "predictor.process_race_data(history)\n",
    "predictor.predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions from Step 5**: Betting £1 randomly on 1040 races results in an overall loss of £156 :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6: Analyse factors to understand if they have influence on the outcome of races. Bill Benter suggested the following attributes:\n",
    "\n",
    "Current condition:\n",
    "- performance in recent races\n",
    "- time since last race\n",
    "- recent workout data\n",
    "- age of horse\n",
    "\n",
    "Past performance:\n",
    "- finishing position in past races\n",
    "- lengths behind winner in past races\n",
    "- normalized times of past races\n",
    "\n",
    "Adjustments to past performance:\n",
    "- strength of competition in past races\n",
    "- weight carried in past races\n",
    "- jockey's contribution to past performances\n",
    "- compensation for bad luck in past races\n",
    "- compensation for advantageous or disadvantageous post position in past races\n",
    "\n",
    "Present race situational factors:\n",
    "- weight to be carried\n",
    "- today's jockey's ability\n",
    "- advantages or disadvantages of the assigned post position\n",
    "\n",
    "Preferences which could influence the horse's performance in today's race:\n",
    "- distance preference\n",
    "- surface preference (turf vs dirt)\n",
    "- condition of surface preference (wet vs dry)\n",
    "- specific track preference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6.1: Define abstract feature factory for feature to the daily results that will be used to inform predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "class FeatureFactory:\n",
    "    @abstractmethod\n",
    "    def add_features(self, history: pd.DataFrame, daily_results : pd.DataFrame) -> pd.DataFrame:\n",
    "        pass\n",
    "\n",
    "\n",
    "class FeaturePredictor(RacePredictor):\n",
    "    def __init__(self, feature_factory: FeatureFactory) -> None:\n",
    "        super().__init__()\n",
    "        self.__feature_factory = feature_factory\n",
    "        self.__features = None\n",
    "\n",
    "    @property\n",
    "    def features(self):\n",
    "        return self.__features\n",
    "\n",
    "    def process_filtered_results(self, daily_results : pd.DataFrame) -> None:\n",
    "        daily_results_with_new_features = self.__feature_factory.add_features(self.history, daily_results.copy())\n",
    "        self.__features = daily_results_with_new_features if self.__features is None else pd.concat([self.__features, daily_results_with_new_features])\n",
    "        predictions = self.calculate_predictions(daily_results_with_new_features)\n",
    "        self._update_predictions(predictions)\n",
    "    \n",
    "    @abstractmethod\n",
    "    def calculate_predictions(self, daily_results : pd.DataFrame) -> pd.DataFrame:\n",
    "        pass\n",
    "\n",
    "    def after_process_data(self) -> None:\n",
    "        super().after_process_data()\n",
    "        print(self.aggregate_prediction_summary())\n",
    "\n",
    "\n",
    "class FeatureBuilder(RaceDataProcessorIgnoringUnknownRunnersOrJockies):\n",
    "    def __init__(self, feature_factories: List[FeatureFactory]) -> None:\n",
    "        super().__init__()\n",
    "        self.__feature_factories = feature_factories\n",
    "        self.__features = None\n",
    "\n",
    "    @property\n",
    "    def features(self):\n",
    "        return self.__features\n",
    "\n",
    "    def process_filtered_results(self, daily_results : pd.DataFrame) -> None:\n",
    "        daily_results_with_new_features = daily_results.copy()\n",
    "        for feature_factory in self.__feature_factories:\n",
    "            daily_results_with_new_features = feature_factory.add_features(self.history, daily_results_with_new_features)\n",
    "        self.__features = daily_results_with_new_features if self.__features is None else pd.concat([self.__features, daily_results_with_new_features])\n",
    "\n",
    "\n",
    "\n",
    "class LowestValueFeaturePredictor(FeaturePredictor):\n",
    "    def __init__(self, feature_factory: FeatureFactory, prediction_feature_name: str, drop_races_with_missing_feature: bool = False) -> None:\n",
    "        super().__init__(feature_factory)\n",
    "        self.__prediction_feature_name = prediction_feature_name\n",
    "        self.__drop_races_with_missing_features = drop_races_with_missing_feature\n",
    "\n",
    "    def calculate_predictions(self, daily_results: pd.DataFrame) -> pd.DataFrame:\n",
    "        if self.__drop_races_with_missing_features:\n",
    "            predictable = daily_results.groupby('RaceId').filter(lambda g: g.isnull().values.sum() == 0)\n",
    "        else:\n",
    "            predictable = daily_results.dropna(axis=0, subset=[self.__prediction_feature_name])\n",
    "\n",
    "        predictions = predictable.sort_values(self.__prediction_feature_name, ascending=True).groupby('RaceId').first().copy()\n",
    "        predictions['PredictedPosition'] = 1\n",
    "        return predictions\n",
    "\n",
    "\n",
    "class HighestValueFeaturePredictor(FeaturePredictor):\n",
    "    def __init__(self, feature_factory: FeatureFactory, prediction_feature_name: str, drop_races_with_missing_feature: bool = False) -> None:\n",
    "        super().__init__(feature_factory)\n",
    "        self.__prediction_feature_name = prediction_feature_name\n",
    "        self.__drop_races_with_missing_features = drop_races_with_missing_feature\n",
    "\n",
    "    def calculate_predictions(self, daily_results: pd.DataFrame) -> pd.DataFrame:\n",
    "        if self.__drop_races_with_missing_features:\n",
    "            predictable = daily_results.groupby('RaceId').filter(lambda g: g.isnull().values.sum() == 0)\n",
    "        else:\n",
    "            predictable = daily_results.dropna(axis=0, subset=[self.__prediction_feature_name])\n",
    "\n",
    "        predictions = predictable.sort_values(self.__prediction_feature_name, ascending=False).groupby('RaceId').first().copy()\n",
    "        predictions['PredictedPosition'] = 1\n",
    "        return predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6.2 Predict using performance in recent races. \n",
    "\n",
    "1. For each race in the last x months, sum the overall beaten distance and divide by the number of races (to average the performance over the period - since some horses may have ran more races than others in the given time frame)\n",
    "1. Predict that the horse with be best/lowers past performance will win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecentRacePerformanceFeatureFactory(FeatureFactory):\n",
    "    def __init__(self, days_to_process : int = 15) -> None:\n",
    "        super().__init__()\n",
    "        self.__days_to_process = days_to_process\n",
    "\n",
    "\n",
    "    def add_features(self, history: pd.DataFrame, daily_results: pd.DataFrame) -> pd.DataFrame:\n",
    "        history_end = history['Off'].max().date()\n",
    "        recent_history_start = history_end - timedelta(days=self.__days_to_process)\n",
    "        recent_history = history[history['Off'].dt.date >= recent_history_start]\n",
    "\n",
    "        horse_performance = recent_history.groupby('HorseId').apply(lambda g: self.__calculate_overall_horse_performance(g))\n",
    "\n",
    "        daily_results_with_new_features = pd.merge(daily_results, horse_performance, how='left', on=['HorseId'])\n",
    "        return daily_results_with_new_features\n",
    "\n",
    "    def __calculate_overall_horse_performance(self, race_group: pd.DataFrame) -> pd.Series:\n",
    "        new_columns = {}\n",
    "        new_columns['RaceCount'] = race_group['RaceId'].count()\n",
    "        new_columns['RecentPerformance'] = race_group['OverallBeatenDistance'].sum() / race_group['RaceId'].count()\n",
    "        return pd.Series(new_columns, index=['RaceCount', 'RecentPerformance']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting results using 30 days of recent history\n",
      "Processed 1040 of 1651 races:\n",
      "  Total ignored races: 611 (with unknown runner or jockey)\n",
      "           Predicted        Wins  PercentageWins    GainLoss    Winnings\n",
      "average    33.366667    5.866667       17.343934   -5.910401   27.456266\n",
      "sum      1001.000000  176.000000             NaN -177.312032  823.687968\n",
      "std              NaN         NaN        7.746484   13.360445   16.117111\n",
      "min              NaN         NaN             NaN  -29.000000    3.750000\n",
      "max              NaN         NaN             NaN   17.950000   66.900000\n",
      "skew             NaN         NaN             NaN    0.232433    0.776615\n",
      "  correlation = -0.11712525433480271\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(30, 31):\n",
    "    predictor = LowestValueFeaturePredictor(RecentRacePerformanceFeatureFactory(days_to_process=i), 'RecentPerformance')\n",
    "    print(f'Predicting results using {i} days of recent history')\n",
    "    predictor.process_race_data(history)\n",
    "    correlation = predictor.features[['Wins', 'RecentPerformance']].corr(method='spearman')['Wins']['RecentPerformance']\n",
    "    print(f'  correlation = {correlation}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6.3 Predict using jockey performance in recent races. \n",
    "\n",
    "1. For each race in the last x months, sum the overall beaten distance for a given jockey and divide by the number of races (to average the performance over the period - since some horses may have ran more races than others in the given time frame)\n",
    "1. Predict that the jockey with be best/lowers past performance will win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecentJockeyRacePerformanceFeatureFactory(FeatureFactory):\n",
    "    def __init__(self, days_to_process : int = 15) -> None:\n",
    "        super().__init__()\n",
    "        self.__days_to_process = days_to_process\n",
    "\n",
    "\n",
    "    def add_features(self, history: pd.DataFrame, daily_results: pd.DataFrame) -> pd.DataFrame:\n",
    "        history_end = history['Off'].max().date()\n",
    "        recent_history_start = history_end - timedelta(days=self.__days_to_process)\n",
    "        recent_history = history[history['Off'].dt.date >= recent_history_start]\n",
    "\n",
    "        jockey_performance = recent_history.groupby('JockeyId').apply(lambda g: self.__calculate_jockey_performance(g))\n",
    "\n",
    "        daily_results_with_new_features = pd.merge(daily_results, jockey_performance, how='left', on=['JockeyId'])\n",
    "        return daily_results_with_new_features\n",
    "\n",
    "    def __calculate_jockey_performance(self, race_group: pd.DataFrame) -> pd.Series:\n",
    "        new_columns = {}\n",
    "        new_columns['RaceCount'] = race_group['RaceId'].count()\n",
    "        new_columns['RecentJockeyPerformance'] = race_group['OverallBeatenDistance'].sum() / race_group['RaceId'].count()\n",
    "        return pd.Series(new_columns, index=['RaceCount', 'RecentJockeyPerformance']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting results using 30 days of recent jockey history\n",
      "Processed 1040 of 1651 races:\n",
      "  Total ignored races: 611 (with unknown runner or jockey)\n",
      "           Predicted        Wins  PercentageWins    GainLoss    Winnings\n",
      "average    34.666667    5.633333       16.324256   -5.227456   29.439211\n",
      "sum      1040.000000  169.000000             NaN -156.823665  883.176335\n",
      "std              NaN         NaN        7.787383   15.359460   17.800923\n",
      "min              NaN         NaN             NaN  -29.875000    0.000000\n",
      "max              NaN         NaN             NaN   45.000000   83.000000\n",
      "skew             NaN         NaN             NaN    0.989620    0.981410\n",
      "  correlation = -0.007379161185814985\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(30, 31):\n",
    "    predictor = LowestValueFeaturePredictor(RecentJockeyRacePerformanceFeatureFactory(days_to_process=i), 'RecentJockeyPerformance')\n",
    "    print(f'Predicting results using {i} days of recent jockey history')\n",
    "    predictor.process_race_data(history)\n",
    "    correlation = predictor.features[['Wins', 'RecentJockeyPerformance']].corr(method='spearman')['Wins']['RecentJockeyPerformance']\n",
    "    print(f'  correlation = {correlation}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1040 of 1651 races:\n",
      "  Total ignored races: 611 (with unknown runner or jockey)\n"
     ]
    }
   ],
   "source": [
    "builder = FeatureBuilder([RecentJockeyRacePerformanceFeatureFactory(), RecentRacePerformanceFeatureFactory()])\n",
    "builder.process_race_data(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = builder.features[['Wins', 'RecentJockeyPerformance', 'RecentPerformance', 'Age', 'WeightInPounds']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wins                       1.000000\n",
       "RecentJockeyPerformance   -0.000493\n",
       "RecentPerformance         -0.131942\n",
       "Age                        0.001105\n",
       "WeightInPounds             0.073938\n",
       "Name: Wins, dtype: float64"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.corr(method='spearman')['Wins']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_horses = history[['HorseId', 'RaceId']].groupby('HorseId').count().reset_index().sort_values('RaceId', ascending=False)['HorseId'].head(10).to_list()\n",
    "top_horse_races = history[history['HorseId'].isin(top_horses)]['RaceId'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RaceType</th>\n",
       "      <th>WeightInPounds</th>\n",
       "      <th>HorseId</th>\n",
       "      <th>RaceId</th>\n",
       "      <th>Surface</th>\n",
       "      <th>Going</th>\n",
       "      <th>Wins</th>\n",
       "      <th>RaceTimeInSeconds</th>\n",
       "      <th>DistanceInMeters</th>\n",
       "      <th>Speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6401</th>\n",
       "      <td>Other</td>\n",
       "      <td>130</td>\n",
       "      <td>1431174</td>\n",
       "      <td>798414</td>\n",
       "      <td>AllWeather</td>\n",
       "      <td>Standard</td>\n",
       "      <td>0</td>\n",
       "      <td>61.4700</td>\n",
       "      <td>1005</td>\n",
       "      <td>16.349439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12802</th>\n",
       "      <td>Other</td>\n",
       "      <td>130</td>\n",
       "      <td>1431174</td>\n",
       "      <td>802356</td>\n",
       "      <td>AllWeather</td>\n",
       "      <td>Standard</td>\n",
       "      <td>0</td>\n",
       "      <td>61.5200</td>\n",
       "      <td>1005</td>\n",
       "      <td>16.336151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6002</th>\n",
       "      <td>Other</td>\n",
       "      <td>132</td>\n",
       "      <td>1431174</td>\n",
       "      <td>810161</td>\n",
       "      <td>AllWeather</td>\n",
       "      <td>Standard</td>\n",
       "      <td>0</td>\n",
       "      <td>61.5200</td>\n",
       "      <td>1005</td>\n",
       "      <td>16.336151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6631</th>\n",
       "      <td>Other</td>\n",
       "      <td>135</td>\n",
       "      <td>1431174</td>\n",
       "      <td>819781</td>\n",
       "      <td>AllWeather</td>\n",
       "      <td>Standard</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0300</td>\n",
       "      <td>1005</td>\n",
       "      <td>16.201838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10850</th>\n",
       "      <td>Other</td>\n",
       "      <td>139</td>\n",
       "      <td>1431174</td>\n",
       "      <td>801573</td>\n",
       "      <td>AllWeather</td>\n",
       "      <td>Standard</td>\n",
       "      <td>0</td>\n",
       "      <td>61.0100</td>\n",
       "      <td>1005</td>\n",
       "      <td>16.472709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>Other</td>\n",
       "      <td>139</td>\n",
       "      <td>3564056</td>\n",
       "      <td>790519</td>\n",
       "      <td>Turf</td>\n",
       "      <td>Soft</td>\n",
       "      <td>1</td>\n",
       "      <td>86.4700</td>\n",
       "      <td>1407</td>\n",
       "      <td>16.271539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10875</th>\n",
       "      <td>Other</td>\n",
       "      <td>139</td>\n",
       "      <td>3564056</td>\n",
       "      <td>791991</td>\n",
       "      <td>Turf</td>\n",
       "      <td>Soft</td>\n",
       "      <td>0</td>\n",
       "      <td>85.0425</td>\n",
       "      <td>1407</td>\n",
       "      <td>16.544669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11165</th>\n",
       "      <td>Other</td>\n",
       "      <td>139</td>\n",
       "      <td>3564056</td>\n",
       "      <td>791991</td>\n",
       "      <td>Turf</td>\n",
       "      <td>Soft</td>\n",
       "      <td>0</td>\n",
       "      <td>85.0425</td>\n",
       "      <td>1407</td>\n",
       "      <td>16.544669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15255</th>\n",
       "      <td>Other</td>\n",
       "      <td>138</td>\n",
       "      <td>3564056</td>\n",
       "      <td>796464</td>\n",
       "      <td>Turf</td>\n",
       "      <td>Very Soft</td>\n",
       "      <td>0</td>\n",
       "      <td>105.9000</td>\n",
       "      <td>1608</td>\n",
       "      <td>15.184136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15512</th>\n",
       "      <td>Other</td>\n",
       "      <td>138</td>\n",
       "      <td>3564056</td>\n",
       "      <td>796464</td>\n",
       "      <td>Turf</td>\n",
       "      <td>Very Soft</td>\n",
       "      <td>0</td>\n",
       "      <td>105.9000</td>\n",
       "      <td>1608</td>\n",
       "      <td>15.184136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>368 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RaceType  WeightInPounds  HorseId  RaceId     Surface      Going  Wins  \\\n",
       "6401     Other             130  1431174  798414  AllWeather   Standard     0   \n",
       "12802    Other             130  1431174  802356  AllWeather   Standard     0   \n",
       "6002     Other             132  1431174  810161  AllWeather   Standard     0   \n",
       "6631     Other             135  1431174  819781  AllWeather   Standard     0   \n",
       "10850    Other             139  1431174  801573  AllWeather   Standard     0   \n",
       "...        ...             ...      ...     ...         ...        ...   ...   \n",
       "1523     Other             139  3564056  790519        Turf       Soft     1   \n",
       "10875    Other             139  3564056  791991        Turf       Soft     0   \n",
       "11165    Other             139  3564056  791991        Turf       Soft     0   \n",
       "15255    Other             138  3564056  796464        Turf  Very Soft     0   \n",
       "15512    Other             138  3564056  796464        Turf  Very Soft     0   \n",
       "\n",
       "       RaceTimeInSeconds  DistanceInMeters      Speed  \n",
       "6401             61.4700              1005  16.349439  \n",
       "12802            61.5200              1005  16.336151  \n",
       "6002             61.5200              1005  16.336151  \n",
       "6631             62.0300              1005  16.201838  \n",
       "10850            61.0100              1005  16.472709  \n",
       "...                  ...               ...        ...  \n",
       "1523             86.4700              1407  16.271539  \n",
       "10875            85.0425              1407  16.544669  \n",
       "11165            85.0425              1407  16.544669  \n",
       "15255           105.9000              1608  15.184136  \n",
       "15512           105.9000              1608  15.184136  \n",
       "\n",
       "[368 rows x 10 columns]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = history[history['HorseId'].isin(top_horses)][['RaceType', 'WeightInPounds', 'HorseId', 'RaceId', 'Surface', 'Going', 'Wins', 'RaceTimeInSeconds', 'DistanceInMeters']]\n",
    "df['Speed'] = df['DistanceInMeters'] / df['RaceTimeInSeconds']\n",
    "df.sort_values([\"HorseId\", \"Surface\", \"Going\", \"DistanceInMeters\", \"WeightInPounds\"])\n",
    "# TODO: calculate youngest horse in a given race, least weight, days since last race \n",
    "# speed on race type, surface, and going and adjust for weight carried\n",
    "# - how does these features correlate with wins?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WeightInPounds</th>\n",
       "      <th>Speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WeightInPounds</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.165697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Speed</th>\n",
       "      <td>-0.165697</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                WeightInPounds     Speed\n",
       "WeightInPounds        1.000000 -0.165697\n",
       "Speed                -0.165697  1.000000"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['WeightInPounds', 'Speed']].corr()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8e284ee3255a07ad8bf76694974743c4c81cb57e7c969474d752d949b11d721e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
