{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --quiet --upgrade pip \n",
    "%pip install numpy --quiet\n",
    "%pip install Pandas --quiet\n",
    "%pip install sklearn --quiet\n",
    "%pip install ipywidgets --quiet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Horse Racing Results Predictor #\n",
    "\n",
    "The American professional gambler [Bill Benter](https://en.wikipedia.org/wiki/Bill_Benter) is said to have made earned nearly $1 billion through the development of one of the most successful analysis computer software programs in the horse racing market.\n",
    "\n",
    "Bill published his techniques in the paper [Computer-Based Horse Race Handicapping and Wagering Systems](https://www.gwern.net/docs/statistics/decision/1994-benter.pdf). \n",
    "\n",
    "The [YouTube Video by Ken Jee](https://www.youtube.com/watch?v=KEeUR8UDy-s) outlines how he did it, how difficult it was, and discusses whether it is likely to be able to replicate this feat today (hint: Ken thinks it highly unlikely for a number of reasons).\n",
    "\n",
    "Inspired by video, this notebook examines the possibility of replicating Bill's success using data from modern day UK races.\n",
    "\n",
    "**NOTE: This is a fun examination of the technique the can be used in predicting races. It is not intended to be accurate or valid. The author accepts no responsibility for the correctness, completeness or quality of the information provided. Please do not use this information to place any real-world bets. Gambling odds are always skewed in favour of the bookmaker and you will lose in the long run.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from abc import ABC, abstractmethod\n",
    "from datetime import datetime, date"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load in the historic race data and ignore any horse that didn't complete the race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from datetime import timedelta\n",
    "results_files = glob.glob('Results_*.csv')\n",
    "results_files\n",
    "\n",
    "history = pd.concat([pd.read_csv(f) for f in results_files])\n",
    "history = history[history['ResultStatus'] == 'CompletedRace']\n",
    "history['Off'] =  pd.to_datetime(history['Off'], format='%m/%d/%Y %H:%M:%S')\n",
    "history['Wins'] = history.apply(lambda r: 1 if r['FinishingPosition'] == 1 else 0, axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse factors to understand if they have influence on the outcome of races. \n",
    "\n",
    "Bill Benter suggested the following attributes:\n",
    "\n",
    "Current condition:\n",
    "- performance in recent races\n",
    "- time since last race\n",
    "- recent workout data\n",
    "- age of horse\n",
    "\n",
    "Past performance:\n",
    "- finishing position in past races\n",
    "- lengths behind winner in past races\n",
    "- normalized times of past races\n",
    "\n",
    "Adjustments to past performance:\n",
    "- strength of competition in past races\n",
    "- weight carried in past races\n",
    "- jockey's contribution to past performances\n",
    "- compensation for bad luck in past races\n",
    "- compensation for advantageous or disadvantageous post position in past races\n",
    "\n",
    "Present race situational factors:\n",
    "- weight to be carried\n",
    "- today's jockey's ability\n",
    "- advantages or disadvantages of the assigned post position\n",
    "\n",
    "Preferences which could influence the horse's performance in today's race:\n",
    "- distance preference\n",
    "- surface preference (turf vs dirt)\n",
    "- condition of surface preference (wet vs dry)\n",
    "- specific track preference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races = history[['RaceId', 'CourseId', 'RaceType', 'Off', 'DecimalOdds', 'OfficialRating', 'RacingPostRating', 'TopSpeedRating',\n",
    "       'DistanceInMeters', 'Going', 'Surface', 'HorseId', 'HorseName', 'JockeyId', 'JockeyName',\n",
    "       'Age', 'HeadGear', 'RaceCardNumber','StallNumber', 'WeightInPounds', \n",
    "       'FinishingPosition','OverallBeatenDistance', 'RaceTimeInSeconds', 'Wins']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expand categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surface_categories = [\"Surface_AllWeather\", \"Surface_Dirt\", \"Surface_Turf\"]\n",
    "races = races.drop(surface_categories + [\"Surface_Unknown\"], axis=1, errors='ignore')\n",
    "races[\"SurfaceTemp\"] = races[\"Surface\"]\n",
    "races = pd.get_dummies(races, prefix=\"Surface\", columns=[\"SurfaceTemp\"], dtype=float)\n",
    "races = races.drop(\"Surface_Unknown\", axis=1) # Drop unknown surface as only small number.\n",
    "races[surface_categories].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise going based on rules here: https://www.racingpost.com/guide-to-racing/what-is-the-going-ann7h6W6VB3b/\n",
    "# Values should be: Firm, Good_To_Firm, Good, Good_To_Soft, Soft, Heavy\n",
    "norm_map = ({\n",
    "    \"Good\": \"Good\", \n",
    "    \"Standard\": \"Good\",\n",
    "    \"Soft\": \"Soft\",\n",
    "    \"Good To Soft\": \"Good_To_Soft\",\n",
    "    \"Good To Firm\": \"Good_To_Firm\",\n",
    "    \"Heavy\": \"Heavy\",\n",
    "    \"Good To Yielding\": \"Good_To_Soft\",    \n",
    "    \"Yielding\": \"Good_To_Soft\",\n",
    "    \"Standard To Slow\": \"Good_To_Soft\",  \n",
    "    \"Very Soft\": \"Heavy\",\n",
    "    \"Fast\": \"Firm\",\n",
    "    \"Firm\": \"Firm\",\n",
    "    \"Soft To Heavy\": \"Heavy\",    \n",
    "    \"Yielding To Soft\": \"Soft\",\n",
    "    \"Slow\": \"Soft\",\n",
    "    \"Sloppy\": \"Heavy\",\n",
    "    \"Muddy\": \"Heavy\",\n",
    "    \"Frozen\": \"Heavy\"\n",
    "})\n",
    "\n",
    "races[\"NormGoing\"] = races[\"Going\"].map(norm_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "going_categories  = [\"Going_Good\", \"Going_Good_To_Soft\", \"Going_Soft\", \"Going_Good_To_Firm\", \"Going_Firm\", \"Going_Heavy\"]\n",
    "races = races.drop(going_categories, axis=1, errors='ignore')\n",
    "races = pd.get_dummies(races, prefix=\"Going\", columns=[\"NormGoing\"], dtype=float)\n",
    "races[going_categories].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_type_categories = [\"RaceType_Other\", \"RaceType_Hurdle\", \"RaceType_SteepleChase\", \"RaceType_Flat\"]\n",
    "races = races.drop(race_type_categories, axis=1, errors='ignore')\n",
    "races[\"RaceTypeTemp\"] = races[\"RaceType\"]\n",
    "races = pd.get_dummies(races, prefix=\"RaceType\", columns=[\"RaceTypeTemp\"], dtype=float)\n",
    "races[race_type_categories].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races[\"DistanceInMeters\"].hist(bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Horse Stats\n",
    "\n",
    "Calculate the speed of each horse in the race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races[\"Speed\"] = races[\"DistanceInMeters\"] / races[\"RaceTimeInSeconds\"]\n",
    "\n",
    "# Deal with invalid data (usually invalid race time) - fastest horse (over short distance) 55mps or approx 25 m/s\n",
    "races.loc[races[\"Speed\"] > 25, \"Speed\"] = np.nan\n",
    "\n",
    "races.plot.scatter(x=\"DistanceInMeters\", y=\"Speed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deal with invalid data - occasionally weight will be undefined (usually zero)\n",
    "races.loc[races[\"WeightInPounds\"] < 10, \"WeightInPounds\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the number of horse in each race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = races.groupby(['RaceId']).apply(lambda g: pd.Series({'HorseCount': g['RaceId'].count()}, index=['HorseCount']))\n",
    "races = pd.merge(races, groups, how='left', on=['RaceId'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define feature factory abstraction that calculates feature values based on previous history (either in total or over a time window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "\n",
    "class RaceDataProcessor(ABC):\n",
    "\n",
    "    def before_process_data(self, df: pd.DataFrame) -> None:\n",
    "        # Update the underlying DataFrame before processing to e.g. set default values for new features\n",
    "        pass\n",
    "\n",
    "    def update(self, df : pd.DataFrame, history : pd.DataFrame, daily_slice : pd.DataFrame) -> None:\n",
    "        # Update the processor with data\n",
    "        pass\n",
    "\n",
    "\n",
    "    def process_race_data(self, df : pd.DataFrame) -> None:\n",
    "        df_start = df['Off'].min().date()\n",
    "        slice_start = df_start + timedelta(days=1)\n",
    "        df_end = df['Off'].max().date() + timedelta(days=1)\n",
    "        \n",
    "        days = (df_end - slice_start).days\n",
    "        f = IntProgress(min=0, max=days) # instantiate the bar\n",
    "        display(f)\n",
    "\n",
    "        self.before_process_data(df)\n",
    "        while slice_start < df_end:\n",
    "            slice_end = slice_start + timedelta(days=1)\n",
    "            history = df[df['Off'].dt.date < slice_start]\n",
    "            daily_slice = df[(df['Off'].dt.date >= slice_start) & (df['Off'].dt.date < slice_end)]\n",
    "            self.update(df, history, daily_slice)\n",
    "            slice_start = slice_end\n",
    "            f.value += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate, for each race, whether the horse and jockey are known (i.e. have previously been involved in a race)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CalculateRacesWithKnownHorsesAndJockeys(RaceDataProcessor):\n",
    "    def before_process_data(self, df: pd.DataFrame) -> None:\n",
    "        df[\"KnownHorseAndJockey\"] = False\n",
    "\n",
    "    def update(self, df : pd.DataFrame, history : pd.DataFrame, daily_slice : pd.DataFrame) -> None:\n",
    "        known_jockeys = history['JockeyId'].unique().tolist()\n",
    "        known_runners = history['HorseId'].unique().tolist()\n",
    "        temp = daily_slice.groupby('RaceId').apply(lambda g: self.__calculate_counts_for_race_group(g, known_jockeys, known_runners))\n",
    "        temp = temp[(temp['HorseCount'] == temp['KnownJockeyCount']) & (temp['HorseCount'] == temp['KnownHorseCount'])]\n",
    "        races_with_known_horses_and_jockeys = temp.reset_index()['RaceId'].unique().tolist()\n",
    "        df.loc[df['RaceId'].isin(races_with_known_horses_and_jockeys), \"KnownHorseAndJockey\"] = True\n",
    "\n",
    "    def __calculate_counts_for_race_group(self, race_group, known_jockeys, known_runners) -> pd.Series:\n",
    "        new_columns = {'HorseCount': race_group['HorseId'].count()}\n",
    "        new_columns['KnownHorseCount'] = race_group[race_group['HorseId'].isin(known_runners)]['HorseId'].count()\n",
    "        new_columns['KnownJockeyCount'] = race_group[race_group['JockeyId'].isin(known_jockeys)]['JockeyId'].count()\n",
    "        return pd.Series(new_columns, index=['HorseCount', 'KnownHorseCount', 'KnownJockeyCount']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CalculateRacesWithKnownHorsesAndJockeys().process_race_data(races)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate stats for each horse in the given daily slice based on the history up until that point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CalculateHorsesStats(RaceDataProcessor):\n",
    "    NUMBER_OF_PRIOR_RACES = \"NumberOfPriorRaces\"\n",
    "    LAST_RACE_GOING = \"LastRaceGoing\"\n",
    "    LAST_RACE_SURFACE = \"LastRaceSurface\"\n",
    "    LAST_RACE_DISTANCE = \"LastRaceDistanceInMeters\"\n",
    "    LAST_RACE_WEIGHT = \"LastRaceWeightInPounds\"\n",
    "    LAST_RACE_SPEED = \"LastRaceSpeed\"\n",
    "    DAYS_REST_SINCE_LAST_RACE = \"DaysRested\"\n",
    "    LAST_RACE_ODDS = \"LastRaceDecimalOdds\"\n",
    "    LAST_RACE_OFFICIAL_RATING = \"LastRaceOfficialRating\"\n",
    "    LAST_RACE_RACING_POST_RATING = \"LastRaceRacingPostRating\"\n",
    "    LAST_RACE_TOP_SPEED_RATING = \"LastRaceTopSpeedRating\"\n",
    "    AVG_RELATIVE_FINISHING_POSITION = \"LastRaceAvgRelFinishingPosition\"\n",
    "    ONE_DAY = np.timedelta64(1, 'D')\n",
    "\n",
    "    def before_process_data(self, df: pd.DataFrame) -> None:\n",
    "        df.loc[:, self.NUMBER_OF_PRIOR_RACES] = 1\n",
    "        df.loc[:, self.LAST_RACE_GOING] = np.nan\n",
    "        self.new_column_names = ([\n",
    "            self.NUMBER_OF_PRIOR_RACES,\n",
    "            self.LAST_RACE_GOING,\n",
    "            self.LAST_RACE_SURFACE,\n",
    "            self.LAST_RACE_DISTANCE,\n",
    "            self.LAST_RACE_WEIGHT,\n",
    "            self.LAST_RACE_SPEED,\n",
    "            self.DAYS_REST_SINCE_LAST_RACE,\n",
    "            self.LAST_RACE_ODDS,\n",
    "            self.LAST_RACE_OFFICIAL_RATING,\n",
    "            self.LAST_RACE_RACING_POST_RATING,\n",
    "            self.LAST_RACE_TOP_SPEED_RATING,\n",
    "            self.AVG_RELATIVE_FINISHING_POSITION] + \n",
    "            [f\"LastRace{surface}\" for surface in surface_categories] +\n",
    "            [f\"LastRace{going}\" for going in going_categories] +\n",
    "            [f\"LastRace{race_type_category}\" for race_type_category in race_type_categories])\n",
    "\n",
    "    def update(self, df : pd.DataFrame, history : pd.DataFrame, daily_slice : pd.DataFrame) -> None:\n",
    "        slice_date = np.datetime64(daily_slice[\"Off\"].min().date())\n",
    "        slice_horses = daily_slice[\"HorseId\"].unique().tolist()\n",
    "        horse_history = history[history[\"HorseId\"].isin(slice_horses)].sort_values([\"HorseId\", \"Off\"], ascending=[True, False])\n",
    "        if len(horse_history) > 0:\n",
    "            stats = horse_history.groupby(\"HorseId\").apply(lambda g: self.__calculate_counts_for_race_group(slice_date, g))\n",
    "            daily_stats = pd.merge(daily_slice.drop(self.new_column_names, axis=1, errors='ignore'), stats, how=\"left\", on=[\"HorseId\"])\n",
    "            df.loc[df.index.isin(daily_slice.index), self.new_column_names] = daily_stats[self.new_column_names].values\n",
    "\n",
    "    def __calculate_counts_for_race_group(self, current_date: np.datetime64, horse_races: pd.DataFrame) -> pd.Series:\n",
    "        new_columns = {self.NUMBER_OF_PRIOR_RACES: horse_races[\"RaceId\"].count()}\n",
    "        last_race = horse_races.head(1) # Data already ordered in Off descending order\n",
    "        new_columns[self.LAST_RACE_GOING] = last_race[\"Going\"].values[0]\n",
    "        new_columns[self.LAST_RACE_SURFACE] = last_race[\"Surface\"].values[0]\n",
    "        new_columns[self.LAST_RACE_DISTANCE] = last_race[\"DistanceInMeters\"].values[0]\n",
    "        new_columns[self.LAST_RACE_WEIGHT] = last_race[\"WeightInPounds\"].values[0]\n",
    "        new_columns[self.LAST_RACE_SPEED] = last_race[\"Speed\"].values[0]\n",
    "        new_columns[self.DAYS_REST_SINCE_LAST_RACE] = math.ceil((current_date - last_race[\"Off\"].values[0]) / self.ONE_DAY)\n",
    "        new_columns[self.LAST_RACE_ODDS] = last_race[\"DecimalOdds\"].values[0]\n",
    "        new_columns[self.LAST_RACE_OFFICIAL_RATING] = last_race[\"OfficialRating\"].values[0]\n",
    "        new_columns[self.LAST_RACE_RACING_POST_RATING] = last_race[\"RacingPostRating\"].values[0]\n",
    "        new_columns[self.LAST_RACE_TOP_SPEED_RATING] = last_race[\"TopSpeedRating\"].values[0]\n",
    "        new_columns[self.AVG_RELATIVE_FINISHING_POSITION] = (horse_races[\"FinishingPosition\"] / horse_races[\"HorseCount\"]).mean()\n",
    "        for going in going_categories:\n",
    "            new_columns[f\"LastRace{going}\"] = last_race[going].values[0]\n",
    "        for surface in surface_categories:\n",
    "            new_columns[f\"LastRace{surface}\"] = last_race[surface].values[0]\n",
    "        for race_type_category in race_type_categories:\n",
    "            new_columns[f\"LastRace{race_type_category}\"] = last_race[race_type_category].values[0]\n",
    "        return pd.Series(new_columns, index=self.new_column_names) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CalculateHorsesStats().process_race_data(races)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating previous horse performance\n",
    "\n",
    "Now that we have calculated stats for each horse based on the previous races, we can try to figure out if any of the attributes we have relating to previous performance correlate to a horses likelihood of beating another horse in the next race. \n",
    "\n",
    "Possible performance attributes are:\n",
    "\n",
    "- Racing post rating\n",
    "- Official rating\n",
    "- Top speed rating\n",
    "- Odds \n",
    "- Average relative position (i.e. position divided by number of runners in race)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_correlation_of_race_attribute(attribute: str) -> np.float64:\n",
    "    head = races[[\"RaceId\", \"HorseId\", \"FinishingPosition\", attribute]]\n",
    "    cross = pd.merge(head, head, on='RaceId')\n",
    "    head2head = cross[cross[\"HorseId_x\"] > cross[\"HorseId_y\"]].copy().dropna()\n",
    "    head2head[\"XBeatsY\"] = head2head[\"FinishingPosition_x\"] < head2head[\"FinishingPosition_y\"]\n",
    "    head2head[\"Relative\"] = head2head[f\"{attribute}_x\"] - head2head[f\"{attribute}_y\"]\n",
    "    return head2head[[\"XBeatsY\", \"Relative\"]].corr(method=\"spearman\")[\"XBeatsY\"][\"Relative\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp_corr = calculate_correlation_of_race_attribute(\"LastRaceRacingPostRating\")\n",
    "or_corr = calculate_correlation_of_race_attribute(\"LastRaceOfficialRating\")\n",
    "ts_corr = calculate_correlation_of_race_attribute(\"LastRaceTopSpeedRating\")\n",
    "odds_corr = calculate_correlation_of_race_attribute(\"LastRaceDecimalOdds\")\n",
    "lr_corr = calculate_correlation_of_race_attribute(\"LastRaceAvgRelFinishingPosition\")\n",
    "print(f\"Correlation for Racing Post Rating {rp_corr}, Official Rating {or_corr}, Top Speed Rating {ts_corr}, Odds {odds_corr}, Avg finish {lr_corr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusions\n",
    "\n",
    "Racing post rating most strongly correlates with next race performance, other rating attributes not so much.\n",
    "Official rating correlation is particularly poor. The problem with all these rating is that there are many rows where the values are undefined.\n",
    "\n",
    "As expected odds and average finishing position are OK negative correlation indicators of prior performance (i.e. lower values correlate to finishing better). The benefits of these indicators is that they are always available for all horses.\n",
    "\n",
    "However, all these attributes are actually relatively weak on their own (finishing position being the best with a correlation of -0.249). The predictive power is likely to be in combination with other factors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Jockey Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CalculateJockeyStats(RaceDataProcessor):\n",
    "    NUMBER_OF_PRIOR_RACES = \"JockeyNumberOfPriorRaces\"\n",
    "    DAYS_SINCE_LAST_RACE = \"DaysSinceJockeyLastRaced\"\n",
    "    WIN_PERCENTAGE = \"JockeyWinPercentage\"\n",
    "    TOP_THREE_FINISH_PERCENTAGE = \"JockeyTop3Percentage\"\n",
    "    AVG_RELATIVE_FINISHING_POSITION = \"JockeyAvgRelFinishingPosition\"\n",
    "    ONE_DAY = np.timedelta64(1, 'D')\n",
    "\n",
    "\n",
    "    def before_process_data(self, df: pd.DataFrame) -> None:\n",
    "        df.loc[:, self.NUMBER_OF_PRIOR_RACES] = 1\n",
    "        self.new_column_names = [\n",
    "            self.NUMBER_OF_PRIOR_RACES,\n",
    "            self.DAYS_SINCE_LAST_RACE,\n",
    "            self.WIN_PERCENTAGE,\n",
    "            self.TOP_THREE_FINISH_PERCENTAGE,\n",
    "            self.AVG_RELATIVE_FINISHING_POSITION]\n",
    "\n",
    "    def update(self, df : pd.DataFrame, history : pd.DataFrame, daily_slice : pd.DataFrame) -> None:\n",
    "        slice_jockeys = daily_slice[\"JockeyId\"].unique().tolist()\n",
    "        jockey_history = history[history[\"JockeyId\"].isin(slice_jockeys)].sort_values([\"JockeyId\", \"Off\"], ascending=[True, False])\n",
    "        if len(jockey_history) > 0:\n",
    "            slice_date = np.datetime64(daily_slice[\"Off\"].min().date())\n",
    "            stats = jockey_history.groupby(\"JockeyId\").apply(lambda g: self.__calculate_counts_for_race_group(slice_date, g))\n",
    "            daily_stats = pd.merge(daily_slice.drop(self.new_column_names, axis=1, errors='ignore'), stats, how=\"left\", on=[\"JockeyId\"])\n",
    "            df.loc[df.index.isin(daily_slice.index), self.new_column_names] = daily_stats[self.new_column_names].values\n",
    "\n",
    "    def __calculate_counts_for_race_group(self, current_date: np.datetime64, jockey_races: pd.DataFrame) -> pd.Series:\n",
    "        number_of_races = jockey_races[\"RaceId\"].count()\n",
    "        new_columns = {self.NUMBER_OF_PRIOR_RACES: number_of_races}\n",
    "        last_race = jockey_races.head(1) # Data already ordered in Off descending order\n",
    "        new_columns[self.DAYS_SINCE_LAST_RACE] = math.ceil((current_date - last_race[\"Off\"].values[0]) / self.ONE_DAY)\n",
    "        wins = len(jockey_races[jockey_races[\"FinishingPosition\"] == 1])\n",
    "        new_columns[self.WIN_PERCENTAGE] = wins / number_of_races\n",
    "        top_finishes = len(jockey_races[jockey_races[\"FinishingPosition\"] < 4])\n",
    "        new_columns[self.TOP_THREE_FINISH_PERCENTAGE] = top_finishes / number_of_races        \n",
    "        average_position = (jockey_races[\"FinishingPosition\"] / jockey_races[\"HorseCount\"]).mean()\n",
    "        new_columns[self.AVG_RELATIVE_FINISHING_POSITION] = average_position\n",
    "        return pd.Series(new_columns, index=self.new_column_names) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CalculateJockeyStats().process_race_data(races)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wp_corr = calculate_correlation_of_race_attribute(\"JockeyWinPercentage\")\n",
    "pp_corr = calculate_correlation_of_race_attribute(\"JockeyTop3Percentage\")\n",
    "fp_corr = calculate_correlation_of_race_attribute(\"JockeyAvgRelFinishingPosition\")\n",
    "print(f\"Correlation for Win percentage {wp_corr}, place percentage {pp_corr}, average finishing position {fp_corr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusions\n",
    "\n",
    "Win and place percentage are OK positive correlation indicator of prior performance. Average finishing position is an OK negative correlation indicator of prior performance (i.e. lower values correlate to finishing better).\n",
    "\n",
    "However, all these attributes are actually relatively weak on there own (finishing position being the best with a correlation of -0.136). The predictive power is likely to be in combination with other factors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oriental_lilly_races = races[races[\"HorseId\"] == 1439510]\n",
    "oriental_lilly_races[[\"Off\", \"HorseId\", \"HorseName\", \"NumberOfPriorRaces\", \"FinishingPosition\", \"DaysRested\", \"LastRaceAvgRelFinishingPosition\"] + [f\"LastRace{going}\" for going in going_categories]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6901 84857\n",
    "james_races = races[(races[\"JockeyId\"] == 6901)].dropna()\n",
    "james_races[[\"Off\", \"JockeyId\", \"JockeyName\", \"JockeyNumberOfPriorRaces\", \"FinishingPosition\", \"HorseCount\", \"JockeyAvgRelFinishingPosition\", \"JockeyWinPercentage\", \"JockeyTop3Percentage\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races.to_csv(\"Race_Features.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8e284ee3255a07ad8bf76694974743c4c81cb57e7c969474d752d949b11d721e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
